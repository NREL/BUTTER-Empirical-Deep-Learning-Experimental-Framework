SELECT groupname, status, MIN(retry_count) as "min_retry", AVG(retry_count) as "avg_retry", MAX(retry_count) as "max_retry",
       COUNT(*), SUM((EXTRACT(EPOCH FROM end_time) - EXTRACT(EPOCH FROM start_time))) / (60*60*24*365) as "years" FROM jobqueue WHERE groupname = 'fixed_3k_1' GROUP BY groupname, status;

select COUNT(id) from log AS log
    where groupname IN ('fixed_3k_1', 'fixed_3k_0', 'fixed_01', 'exp00', 'exp01') AND
    (NOT EXISTS (SELECT id FROM materialized_experiments_3_base AS d WHERE d.id = log.id) OR
     NOT EXISTS (SELECT id FROM materialized_experiments_3_val_loss AS d WHERE d.id = log.id) OR
    NOT EXISTS (SELECT id FROM materialized_experiments_3_history AS d WHERE d.id = log.id));

select count(*) from log;

SELECT job_length,  (EXTRACT(epoch FROM job_length) * 1000)::int as run_time FROM materialized_experiments_3_base LIMIT 10;

ALTER TABLE materialized_experiments_3_history ADD COLUMN val_loss real[];
vacuum FULL materialized_experiments_3_val_loss;
SELECT
            log.id as id,
            log.job as job,
            log.timestamp as timestamp,
            log.groupname as group,
            COALESCE((EXTRACT(epoch FROM (jobqueue.end_time - jobqueue.start_time)) * 1000)::int, -1) AS job_length,
            log.doc as doc
            FROM
                 log AS log,
                 jobqueue
            WHERE jobqueue.start_time IS NOT NULL
LIMIT 10;

alter table materialized_experiments_3_base drop column job_length;
alter table materialized_experiments_3_base add column runtime integer;
alter table materialized_experiments_3_base alter column runtime set not null;
VACUUM FULL materialized_experiments_3_history;
update materialized_experiments_3_base
set runtime = -1 WHERE runtime IS NULL;

select * from strings;

SELECT DISTINCT(log.doc->'config'->'residual_mode') FROM log
WHERE
    groupname = 'fixed_3k_1';

select budget, depth, avg(a.val) as value, count(a.val) as count, a.epoch
    from
        materialized_experiments_3_base base,
        materialized_experiments_3_loss loss,
        unnest(loss.val_loss) WITH ORDINALITY as a(val, epoch)
    WHERE
        base.id = loss.id and
        label_noise = 0.0::real and
        learning_rate = 0.0001::real and
        groupname = 1176 and
        dataset = 1113 and
        topology = 1114 and
        residual_mode = 1115
    GROUP BY budget, depth, epoch
    ORDER BY budget, depth, epoch;

select distinct(learning_rate)
    from
        materialized_experiments_3_base base
    WHERE
        groupname = 1176 and
        dataset = 1113 and
        topology = 1114 and
        residual_mode = 1115;

select DISTINCT(groupname) from log;

DELETE FROM log where groupname is NULL;

SELECT * FROM materialized_experiments_3_base WHERE materialized_experiments_3_base.job_length IS NULL;


select COUNT(log.id) from log AS log
    where groupname IN ('fixed_3k_1', 'fixed_3k_0', 'fixed_01', 'exp00', 'exp01') AND
    (NOT EXISTS (SELECT id FROM materialized_experiments_3_base AS d WHERE d.id = log.id) OR
     NOT EXISTS (SELECT id FROM materialized_experiments_3_loss AS d WHERE d.id = log.id) OR
    NOT EXISTS (SELECT id FROM materialized_experiments_3_history AS d WHERE d.id = log.id));

SELECT COUNT(*), groupname FROM log where not EXISTS(select uuid from jobqueue where jobqueue.uuid = log.job) GROUP BY  groupname;

SELECT
    log.id as id,
    log.job as job,
    log.timestamp as timestamp,
    log.groupname as groupname,
    (jobqueue.end_time - jobqueue.start_time) AS job_length,
    jobqueue.start_time,
    jobqueue.end_time,
    jobqueue.uuid
    FROM
         log AS log,
         jobqueue
    WHERE
        jobqueue.uuid = log.job AND
        (jobqueue.end_time - jobqueue.start_time) IS NULL;

create table strings
(
    id SMALLINT not NULL GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    value text NOT NULL UNIQUE
);

create index strings_id_value
    on strings (id, value);

create index strings_value_id
    on strings (value, id);




drop table materialized_experiments_2;
create table materialized_experiments_2
(
	id int not null,
	job uuid not null,
	timestamp timestamp not null,
	groupname text not null,
	dataset text not null,
	topology text not null,
	residual_mode text not null,
	budget bigint not null,
	depth smallint not null,
	job_length interval,
	learning_rate real not null,
	optimizer text not null,
	activation text not null,
	epochs int not null,
	batch_size int not null,
	validation_split real not null,
	label_noise real not null,
    loss real[] not null,
    hinge real[] not null,
    accuracy real[] not null,
    val_loss real[] not null,
    val_hinge real[] not null,
    val_accuracy real[] not null,
    squared_hinge real[] not null,
    cosine_similarity real[] not null,
    val_squared_hinge real[] not null,
    mean_squared_error real[] not null,
    mean_absolute_error real[] not null,
    val_cosine_similarity real[] not null,
    val_mean_squared_error real[] not null,
    root_mean_squared_error real[] not null,
    val_mean_absolute_error real[] not null,
    kullback_leibler_divergence real[] not null,
    val_root_mean_squared_error real[] not null,
    mean_squared_logarithmic_error real[] not null,
    val_kullback_leibler_divergence real[] not null,
    val_mean_squared_logarithmic_error real[] not null
);
DELETE FROM materialized_experiments_2 as mat WHERE EXISTS (select id from to_del where to_del.id = mat.id);

SELECT
    t.tablename,
    indexname,
    c.reltuples AS num_rows,
    pg_size_pretty(pg_relation_size(quote_ident(t.tablename)::text)) AS table_size,
    pg_size_pretty(pg_relation_size(quote_ident(indexrelname)::text)) AS index_size,
    CASE WHEN indisunique THEN 'Y'
       ELSE 'N'
    END AS UNIQUE,
    idx_scan AS number_of_scans,
    idx_tup_read AS tuples_read,
    idx_tup_fetch AS tuples_fetched
FROM pg_tables t
LEFT OUTER JOIN pg_class c ON t.tablename=c.relname
LEFT OUTER JOIN
    ( SELECT c.relname AS ctablename, ipg.relname AS indexname, x.indnatts AS number_of_columns, idx_scan, idx_tup_read, idx_tup_fetch, indexrelname, indisunique FROM pg_index x
           JOIN pg_class c ON c.oid = x.indrelid
           JOIN pg_class ipg ON ipg.oid = x.indexrelid
           JOIN pg_stat_all_indexes psai ON x.indexrelid = psai.indexrelid )
    AS foo
    ON t.tablename = foo.ctablename
WHERE t.schemaname='public'
ORDER BY 1,2;

select * FROM
              materialized_experiments_3_base as base,
              materialized_experiments_3_history as hist
WHERE base.id = hist.id AND base.topology = 'rectangle' limit 2;

SELECT pg_size_pretty( pg_total_relation_size('strings') );
SELECT pg_size_pretty( pg_total_relation_size('materialized_experiments_3_base') );
SELECT pg_size_pretty( pg_total_relation_size('materialized_experiments_3_history') );
VACUUM FULL materialized_experiments_3_history;
VACUUM FULL strings;

delete FROM materialized_experiments_3_base;

select * from strings;
select COUNT(*) from materialized_experiments_3_base;

alter table materialized_experiments_3_base
    add column groupname smallint not null,
    add column dataset smallint not null,
    add column topology smallint not null,
    add column residual_mode smallint not null,
    add column optimizer smallint not null,
    add column activation smallint not null,
    add column job_length interval;

create table materialized_experiments_3_base
(
	id int not null PRIMARY KEY,
	job uuid not null,
	timestamp timestamp not null,
	budget bigint not null,
	depth smallint not null,
	learning_rate real not null,
	epochs int not null,
	batch_size int not null,
	validation_split real not null,
	label_noise real not null,
	groupname smallint not null,
    dataset smallint not null,
    topology smallint not null,
    residual_mode smallint not null,
    optimizer smallint not null,
    activation smallint not null,
	job_length interval
);



CREATE INDEX ON materialized_experiments_3_base ("group");

CREATE INDEX ON materialized_experiments_3_base (dataset);
CREATE INDEX ON materialized_experiments_3_base (topology, residual_mode);
CREATE INDEX ON materialized_experiments_3_base (label_noise);
CREATE INDEX ON materialized_experiments_3_base (learning_rate);
CREATE INDEX ON materialized_experiments_3_base (depth);
CREATE INDEX ON materialized_experiments_3_base (budget);

CREATE INDEX ON materialized_experiments_3_base ("group", dataset, learning_rate, label_noise, topology, residual_mode, depth, budget);
CREATE INDEX ON materialized_experiments_3_base ("group", dataset, topology, residual_mode, learning_rate, label_noise, depth, budget);

CREATE INDEX ON materialized_experiments_3_base ("group", dataset, topology, residual_mode, depth);
CREATE INDEX ON materialized_experiments_3_base ("group", dataset, learning_rate, label_noise);
CREATE INDEX ON materialized_experiments_3_base ("group", dataset, budget);



VACUUM log;






-- (id, job, timestamp, budget, depth, learning_rate, epochs, batch_size, validation_split, label_noise, groupname, dataset, topology, residual_mode, optimizer, activation, job_length)
create table materialized_experiments_3_history
(
	id int not null PRIMARY KEY,
    loss real[] not null,
    hinge real[] not null,
    accuracy real[] not null,
    val_loss real[] not null,
    val_hinge real[] not null,
    val_accuracy real[] not null,
    squared_hinge real[] not null,
    cosine_similarity real[] not null,
    val_squared_hinge real[] not null,
    mean_squared_error real[] not null,
    mean_absolute_error real[] not null,
    val_cosine_similarity real[] not null,
    val_mean_squared_error real[] not null,
    root_mean_squared_error real[] not null,
    val_mean_absolute_error real[] not null,
    kullback_leibler_divergence real[] not null,
    val_root_mean_squared_error real[] not null,
    mean_squared_logarithmic_error real[] not null,
    val_kullback_leibler_divergence real[] not null,
    val_mean_squared_logarithmic_error real[] not null
);

create table materialized_experiments_3_loss
(
	id int not null PRIMARY KEY,
    loss real[] not null,
    val_loss real[] not null
);
ALTER TABLE materialized_experiments_3_history DROP COLUMN loss, DROP COLUMN val_loss;
INSERT INTO materialized_experiments_3_loss SELECT id, loss, val_loss from materialized_experiments_3_history ORDER BY id;
VACUUM  materialized_experiments_3_history;

CREATE TABLE to_del AS (SELECT id, COUNT(id) as count
FROM materialized_experiments_2
GROUP BY id
HAVING COUNT(id) > 1 LIMIT 5000);


DELETE FROM materialized_experiments_2 as mat WHERE (
    SELECT COUNT(id) FROM materialized_experiments_2 as ct WHERE ct.id = mat.id)



SELECT COUNT(*)
FROM
     (SELECT id
        FROM materialized_experiments_2
        GROUP BY id
        HAVING COUNT(id) > 1 LIMIT 100) as t;

select COUNT(DISTINCT(id)) from materialized_experiments_2;

select COUNT(*) from log AS log
    where groupname IN ('fixed_3k_0', 'fixed_3k_1') AND NOT EXISTS (SELECT id FROM materialized_experiments_2 AS d WHERE d.id = log.id);

select COUNT(*) from log AS log
    where groupname IN ('fixed_3k_0', 'fixed_3k_1') AND EXISTS (SELECT id FROM materialized_experiments_2 AS d WHERE d.id = log.id);

vacuum materialized_experiments_2;


select count(*) from materialized_experiments_2;

create index materialized_experiments_2_brin_id on materialized_experiments_2 using BRIN(id);
create index materialized_experiments_2_brin_job on materialized_experiments_2 using BRIN(job);
drop index concurrently materialized_experiments_2_brin_groupname;
create index concurrently materialized_experiments_2_brin_groupname on materialized_experiments_2 using BRIN(groupname);
create index materialized_experiments_2_brin_groupname_id on materialized_experiments_2 using BRIN(groupname, id);
create index materialized_experiments_2_brin_groupname_job on materialized_experiments_2 using BRIN(groupname, job);
create index materialized_experiments_2_brin_timestamp on materialized_experiments_2 using BRIN(groupname, timestamp);
create index materialized_experiments_2_brin_dataset on materialized_experiments_2 using BRIN(groupname, dataset);
create index materialized_experiments_2_brin_topology on materialized_experiments_2 using BRIN(groupname, topology);
create index materialized_experiments_2_brin_residual_mode on materialized_experiments_2 using BRIN(groupname, residual_mode);
create index materialized_experiments_2_brin_budget on materialized_experiments_2 using BRIN(groupname, budget);
create index materialized_experiments_2_brin_depth on materialized_experiments_2 using BRIN(groupname, depth);
create index materialized_experiments_2_brin_job_length on materialized_experiments_2 using BRIN(groupname, job_length);
create index materialized_experiments_2_brin_learning_rate on materialized_experiments_2 using BRIN(groupname, learning_rate);
create index materialized_experiments_2_brin_optimizer on materialized_experiments_2 using BRIN(groupname, optimizer);
create index materialized_experiments_2_brin_activation on materialized_experiments_2 using BRIN(groupname, activation);
create index materialized_experiments_2_brin_epochs on materialized_experiments_2 using BRIN(groupname, epochs);
create index materialized_experiments_2_brin_batch_size on materialized_experiments_2 using BRIN(groupname, batch_size);
create index materialized_experiments_2_brin_validation_split on materialized_experiments_2 using BRIN(groupname, validation_split);
create index materialized_experiments_2_brin_label_noise on materialized_experiments_2 using BRIN(groupname, label_noise);

create index materialized_experiments_2_id on materialized_experiments_2 (id);


select id from log where groupname IN ("fixed_3k_1") limit 1;

SELECT *
  FROM information_schema.columns
 WHERE table_schema = 'public'
   AND table_name   = 'materialized_experiments_2'
     ;
SELECT * FROM pg_stat_activity WHERE datname = 'dmpapps'  ORDER BY query;
SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'dmpapps' and username = 'dmpappsops';

select pg_terminate_backend(9206);

SELECT pg_size_pretty( pg_total_relation_size('materialized_experiments_3_base') );
SELECT pg_size_pretty( pg_total_relation_size('materialized_experiments_3_history') );
SELECT pg_size_pretty( pg_total_relation_size('log') );

DELETE FROM materialized_experiments_1;

INSERT INTO strings (value)
    SELECT DISTINCT(topology)
    FROM materialized_experiments_0
    WHERE topology IS NOT NULL
ON CONFLICT (value) DO NOTHING
RETURNING value;

SELECT
    log.id as id,
    log.job as job,
    log.timestamp as timestamp,
    (SELECT id from strings WHERE strings.value = log.groupname) as groupname,
    (SELECT id from strings WHERE strings.value = config.dataset) as dataset,
    (SELECT id from strings WHERE strings.value = config.topology) as topology,
    (SELECT id from strings WHERE strings.value = config.residual_mode) as residual_mode,
    config.budget as budget,
    config.depth as depth,
    (CASE WHEN jsonb_typeof(config.label_noise) = 'number' THEN config.label_noise::real ELSE 0.0 END) AS label_noise,
    history.loss as history_loss,
    history.hinge as history_hinge,
    history.accuracy as history_accuracy,
    history.val_loss as history_val_loss,
    history.val_hinge as history_val_hinge,
    history.val_accuracy as history_val_accuracy,
    history.squared_hinge as history_squared_hinge,
    history.cosine_similarity as history_cosine_similarity,
    history.val_squared_hinge as history_val_squared_hinge,
    history.mean_squared_error as history_mean_squared_error,
    history.mean_absolute_error as history_mean_absolute_error,
    history.val_cosine_similarity as history_val_cosine_similarity,
    history.val_mean_squared_error as history_val_mean_squared_error,
    history.root_mean_squared_error as history_root_mean_squared_error,
    history.val_mean_absolute_error as history_val_mean_absolute_error,
    history.kullback_leibler_divergence as history_kullback_leibler_divergence,
    history.val_root_mean_squared_error as history_val_root_mean_squared_error,
    history.mean_squared_logarithmic_error as history_mean_squared_logarithmic_error,
    history.val_kullback_leibler_divergence as history_val_kullback_leibler_divergence,
    history.val_mean_squared_logarithmic_error as history_val_mean_squared_logarithmic_error
    FROM
         log,
         jsonb_to_record(log.doc->'config') as config (dataset text, topology text, residual_mode text, budget bigint, depth smallint, label_noise jsonb),
         jsonb_to_record(log.doc->'history') as history (
            loss real[],
            hinge real[],
            accuracy real[],
            val_loss real[],
            val_hinge real[],
            val_accuracy real[],
            squared_hinge real[],
            cosine_similarity real[],
            val_squared_hinge real[],
            mean_squared_error real[],
            mean_absolute_error real[],
            val_cosine_similarity real[],
            val_mean_squared_error real[],
            root_mean_squared_error real[],
            val_mean_absolute_error real[],
            kullback_leibler_divergence real[],
            val_root_mean_squared_error real[],
            mean_squared_logarithmic_error real[],
            val_kullback_leibler_divergence real[],
            val_mean_squared_logarithmic_error real[])
    WHERE
        log.groupname = 'fixed_3k_1'
    LIMIT 2;



INSERT INTO materialized_experiments_2
    SELECT
        log.id as id,
        log.job as job,
        log.timestamp as timestamp,
        (SELECT id from strings WHERE strings.value = log.groupname) as groupname,
        (SELECT id from strings WHERE strings.value = config.dataset) as dataset,
        (SELECT id from strings WHERE strings.value = config.topology) as topology,
        (SELECT id from strings WHERE strings.value = config.residual_mode) as residual_mode,
        config.budget as budget,
        config.depth as depth,
        (jobqueue.end_time - jobqueue.start_time) AS job_length,
        (config->'optimizer'->'config'->'learning_rate')::real AS learning_rate,
        (CASE WHEN jsonb_typeof(config.label_noise) = 'number' THEN config.label_noise::real ELSE 0.0 END) AS label_noise,
        history.loss as history_loss,
        history.hinge as history_hinge,
        history.accuracy as history_accuracy,
        history.val_loss as history_val_loss,
        history.val_hinge as history_val_hinge,
        history.val_accuracy as history_val_accuracy,
        history.squared_hinge as history_squared_hinge,
        history.cosine_similarity as history_cosine_similarity,
        history.val_squared_hinge as history_val_squared_hinge,
        history.mean_squared_error as history_mean_squared_error,
        history.mean_absolute_error as history_mean_absolute_error,
        history.val_cosine_similarity as history_val_cosine_similarity,
        history.val_mean_squared_error as history_val_mean_squared_error,
        history.root_mean_squared_error as history_root_mean_squared_error,
        history.val_mean_absolute_error as history_val_mean_absolute_error,
        history.kullback_leibler_divergence as history_kullback_leibler_divergence,
        history.val_root_mean_squared_error as history_val_root_mean_squared_error,
        history.mean_squared_logarithmic_error as history_mean_squared_logarithmic_error,
        history.val_kullback_leibler_divergence as history_val_kullback_leibler_divergence,
        history.val_mean_squared_logarithmic_error as history_val_mean_squared_logarithmic_error
        FROM
             log,
             jobqueue,
             jsonb_to_record(log.doc->'config') as config (dataset text, topology text, residual_mode text, budget bigint, depth smallint, label_noise jsonb),
             jsonb_to_record(log.doc->'history') as history (
                loss real[],
                hinge real[],
                accuracy real[],
                val_loss real[],
                val_hinge real[],
                val_accuracy real[],
                squared_hinge real[],
                cosine_similarity real[],
                val_squared_hinge real[],
                mean_squared_error real[],
                mean_absolute_error real[],
                val_cosine_similarity real[],
                val_mean_squared_error real[],
                root_mean_squared_error real[],
                val_mean_absolute_error real[],
                kullback_leibler_divergence real[],
                val_root_mean_squared_error real[],
                mean_squared_logarithmic_error real[],
                val_kullback_leibler_divergence real[],
                val_mean_squared_logarithmic_error real[])
        WHERE
            jobqueue.uuid = log.job AND
            log.groupname = 'fixed_3k_1';

select * from materialized_experiments_1 limit 1;

SELECT * FROM pg_stat_activity WHERE datname = 'dmpapps'  ORDER BY query;

SELECT *
FROM
     materialized_experiments_3_base as mat,
     materialized_experiments_3_loss as loss
WHERE
    mat.id = loss.id AND
    mat."group" = (SELECT id from strings where value = 'fixed_3k_1')AND
    mat.dataset = (SELECT id from strings where value = '201_pol')AND
    mat.topology = (SELECT id from strings where value = 'rectangle')AND
    mat.learning_rate = (0.0001)::real AND
    mat.label_noise = (0.0)::real;

VACUUM  materialized_experiments_3_base;
--     mat.learning_rate BETWEEN (0.0001 * .999 AND 0.0001 * 1.001)