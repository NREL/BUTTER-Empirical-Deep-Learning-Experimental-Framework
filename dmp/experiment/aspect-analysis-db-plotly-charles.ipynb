{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations in Plotly for the DMP Aspect Test Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from dmp.data.logging import _get_sql_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from joblib import Memory\n",
    "from ipywidgets import interact, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = _get_sql_engine()\n",
    "\n",
    "memory = Memory(location=\"./cache\", verbose=0)\n",
    "\n",
    "def query(query_string):\n",
    "    with db.connect() as engine:\n",
    "        return pd.read_sql(query_string, engine)\n",
    "\n",
    "cached_query = memory.cache(query)\n",
    "\n",
    "def clear_cache():\n",
    "    memory.clear()\n",
    "    \n",
    "options = {\n",
    "    \"dataset\": ['529_pollen',\n",
    "        'sleep',\n",
    "#         'adult',\n",
    "        '537_houses',\n",
    "#         'nursery',\n",
    "        '201_pol',\n",
    "        'mnist',\n",
    "        'connect_4',\n",
    "        'wine_quality_white'],\n",
    "    \"agg\": [\"avg\", \"min\", \"max\"],\n",
    "    \"topology\" : [\"exponential\", \"rectangle\", \"trapezoid\", \"wide_first\"],\n",
    "    \"loss\": ['history_loss', 'history_hinge', 'history_accuracy',\n",
    "       'history_val_loss', 'history_val_hinge', 'history_val_accuracy',\n",
    "       'history_squared_hinge', 'history_cosine_similarity',\n",
    "       'history_val_squared_hinge', 'history_mean_squared_error',\n",
    "       'history_mean_absolute_error', 'history_val_cosine_similarity',\n",
    "       'history_val_mean_squared_error', 'history_root_mean_squared_error',\n",
    "       'history_val_mean_absolute_error',\n",
    "       'history_kullback_leibler_divergence',\n",
    "       'history_val_root_mean_squared_error',\n",
    "       'history_mean_squared_logarithmic_error',\n",
    "       'history_val_kullback_leibler_divergence',\n",
    "       'history_val_mean_squared_logarithmic_error'],\n",
    "    \"residual_mode\": [\"none\", \"full\"],\n",
    "    \"group_select\" : [\"min\", \"max\"],\n",
    "    'depth':[2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20],\n",
    "    'budget': [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384,\n",
    "                32768, 65536, 131072, 262144, 524288, 1048576, 2097152, 4194304,\n",
    "                8388608, 16777216, 33554432],\n",
    "    'color_range': (1.05, 2.5, .05),\n",
    "    'epoch_axis' : ['epoch', 'log_effort', 'effort']\n",
    "    \n",
    "}\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.templates[\"dmp_template\"] = go.layout.Template(\n",
    "    layout=go.Layout(\n",
    "        colorscale={\n",
    "            'diverging':'Temps',\n",
    "            'sequential': 'Viridis_r',\n",
    "            'sequentialminus':'Viridis_r',\n",
    "#             'sequential': 'Agsunset_r',\n",
    "#             'sequentialminus':'Agsunset_r',\n",
    "        }\n",
    "    )\n",
    ")\n",
    "pio.templates.default = 'dmp_template'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[Memory(location=./cache/joblib)]: Flushing completely the cache\n"
     ]
    }
   ],
   "source": [
    "clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_value(df, loss, color_range):\n",
    "    z_label = loss\n",
    "    #     df[\"value\"] = -np.log(np.minimum(df[\"value\"], np.min(df[\"value\"])*4))   \n",
    "#     df[\"value\"] = -np.log(df['value'] / np.min(df['value']))\n",
    "#     df[\"value\"] = -np.log(df['value'] / np.min(df['value']))\n",
    "#     df[\"value\"] = -(df['value'] / np.min(df['value']))\n",
    "\n",
    "    minimizing = True\n",
    "    if 'accuracy' in loss:\n",
    "        df['value'] = 1 - df['value']\n",
    "        df['value'] = np.minimum(np.min(df['value']) * color_range, df['value'])\n",
    "        df[\"value\"] = np.log(df['value'])/np.log(10)\n",
    "        z_label = f'log(1-{loss})'\n",
    "    elif 'loss' in loss:\n",
    "#         df[\"value\"] = -np.exp(1 - df['value']/np.min(df['value']))\n",
    "        df['value'] = np.minimum(np.min(df['value']) * color_range, df['value'])\n",
    "#         df[\"value\"] = -np.log(df['value'])/np.log(10)\n",
    "#         z_label = f'-log({loss})'\n",
    "        \n",
    "        df[\"value\"] = df['value'] / np.abs(np.min(df['value']))\n",
    "        z_label = f'loss / abs(min(loss))'\n",
    "#         df[\"value\"] = -np.log(df['value'] / np.min(df['value']))/np.log(10)\n",
    "#         df[\"value\"] = -df['value'] / np.min(df['value'])\n",
    "    elif 'error' in loss:\n",
    "        df[\"value\"] = df['value'] / np.min(df['value'])\n",
    "        df['value'] = np.minimum(color_range, df['value'])\n",
    "        z_label = f'error / min(error)'\n",
    "    \n",
    "    if minimizing:\n",
    "        best = np.nanmin(df['value'])\n",
    "    else:\n",
    "        best = np.nanmax(df['value'])\n",
    "        \n",
    "    return z_label, minimizing, best\n",
    "\n",
    "def compute_effort(df):\n",
    "    df[\"effort\"] = (df[\"epoch\"] * df[\"config.budget\"].astype(\"float\")).astype(\"float\")\n",
    "    df[\"log_effort\"] = np.log(df[\"effort\"]) / np.log(10)\n",
    "    df['relative_effort'] = df['effort'] / np.min(df['effort'])\n",
    "    df['relative_log_effort'] = np.log(df['relative_effort']) / np.log(10)\n",
    "\n",
    "\n",
    "def get_values_for_categorical_keys(df, partition_keys):\n",
    "    partitions = []\n",
    "    for partition_key in partition_keys:\n",
    "        partition_values = sorted(df[partition_key].unique())\n",
    "        partitions.append(\n",
    "            (partition_key,\n",
    "            {key : index for index, key in enumerate(partition_values)},\n",
    "            partition_values\n",
    "            ))\n",
    "    return tuple(partitions)\n",
    "\n",
    "def partitioned_interpolation(df, partition_keys, interpolation_key, value_key, resolution):\n",
    "    partitions = get_values_for_categorical_keys(df, partition_keys)\n",
    "    \n",
    "    def make_partition_accumulator(i):\n",
    "        index = partitions[i][1]\n",
    "        return [make_partition_accumulator(i + 1) if i < len(partitions) - 1 else ([], []) \n",
    "                for p in range(len(index))]\n",
    "    acc = make_partition_accumulator(0)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        a = acc\n",
    "        for partition_key, index, _ in partitions:\n",
    "            a = a[index[row[partition_key]]]\n",
    "        a[0].append(row[interpolation_key])\n",
    "        a[1].append(row[value_key])\n",
    "\n",
    "    interpolation_series = df[interpolation_key]\n",
    "    interpolation_index = np.linspace(np.min(interpolation_series), np.max(interpolation_series), resolution)\n",
    "    partition_indexes = [np.linspace(0, len(p), len(p)) for p in partitions]\n",
    "    \n",
    "    def do_interpolation(a):\n",
    "        if type(a) is list:\n",
    "            return [do_interpolation(p) for p in a]\n",
    "        func = scipy.interpolate.interp1d(a[0], a[1], kind='linear', bounds_error=False, fill_value=np.NaN)\n",
    "        return func(interpolation_index)            \n",
    "    interpolated = np.array(do_interpolation(acc))\n",
    "    print(f'interpolated {interpolated.shape}')\n",
    "    return partitions, interpolation_index, interpolated\n",
    "\n",
    "\n",
    "def make_2d_heatmap_viz(df, groups, dataset, topology, loss, agg, residual_mode, viz, color_range):\n",
    "    z_label, minimizing, best = setup_value(df, loss, color_range)\n",
    "        \n",
    "    if viz == \"imshow\":\n",
    "        img = df.pivot_table(columns=\"epoch\", index=\"config.budget\", values=\"value\")\n",
    "        fig = px.imshow(img)\n",
    "        fig.update_yaxes(type='category')\n",
    "    elif viz == \"scatter\":\n",
    "        df = df.sort_values([\"epoch\", \"config.budget\"], ascending=[True, False])\n",
    "        df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "        df[\"epoch\"] = df[\"epoch\"].astype(\"str\")\n",
    "        fig = px.scatter(df, x=\"epoch\", y=\"config.budget\", size=\"count\", color=\"value\")\n",
    "    elif viz == \"effort\":\n",
    "        compute_effort(df)\n",
    "        key = 'log_effort'\n",
    "        x_res = 4000\n",
    "        partitions, x_index, interpolated = partitioned_interpolation(df, ['config.budget'], key, 'value', x_res)\n",
    "        fig= px.imshow(interpolated, aspect='auto', zmin=np.min(interpolated), zmax=np.max(interpolated),\n",
    "            x = x_index,\n",
    "            y = [str(b) for b in partitions[0][1]],\n",
    "            labels=dict(x=\"log(Effort)\", y=\"# Parameters\", color=z_label),)\n",
    "        fig.update_yaxes(type='category')\n",
    "    else:\n",
    "        return None\n",
    "    fig.update_layout(title=f\"{z_label} using {loss} for {dataset}, {topology}, residual {residual_mode}\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Heatmap App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95229d95d7f3442186d1de6bdfe23165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value=\"('fixed_01')\", description='groups'), Dropdown(description='dataset', index=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual(**options, viz=[\"volume\", \"scatter\"])\n",
    "def heatmap_app_3d(groups=\"('fixed_01')\", dataset=\"201_pol\", topology=\"trapezoid\", loss=\"history_val_loss\", agg=\"avg\", residual_mode=\"none\", viz=\"volume\", epoch_axis = 'epoch', color_range=1.25):\n",
    "    query_string = f'''\n",
    "    select \"config.budget\", \"config.depth\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "    from\n",
    "        materialized_experiments_0 t,\n",
    "        unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "    WHERE\n",
    "        \"groupname\" IN {groups} and\n",
    "        \"config.dataset\"='{dataset}' and\n",
    "        \"config.topology\"='{topology}' and\n",
    "        \"config.residual_mode\"='{residual_mode}'\n",
    "    GROUP BY epoch, \"config.budget\", \"config.depth\"\n",
    "    ORDER BY epoch, \"config.budget\", \"config.depth\"\n",
    "    '''\n",
    "    df = cached_query(query_string).query(\"count >= 7\")    \n",
    "    value_label, minimizing, best = setup_value(df, loss, color_range)    \n",
    "    if 'effort' in epoch_axis:\n",
    "        compute_effort(df)        \n",
    "    \n",
    "    if viz==\"scatter\":        \n",
    "        return px.scatter_3d(df,\n",
    "                    x='config.depth',\n",
    "                    y='config.budget',\n",
    "                    z=epoch_axis,\n",
    "                    color='value',\n",
    "                    log_y=True,\n",
    "                    opacity=0.25)\n",
    "    elif viz == \"volume\":\n",
    "        x_res = 2000\n",
    "        partition_keys = ['config.budget', 'config.depth']\n",
    "        \n",
    "        if 'effort' in epoch_axis:\n",
    "            partitions, z_index, values = partitioned_interpolation(df, partition_keys, epoch_axis, 'value', x_res)\n",
    "        else:\n",
    "            partition_keys.append(epoch_axis)\n",
    "            partitions = get_values_for_categorical_keys(df, partition_keys)\n",
    "            z_index = np.array(list(partitions[2][1].keys()))\n",
    "            values = np.empty((len(partitions[0][2]), len(partitions[1][2]), len(partitions[2][2])))\n",
    "            values[:] = np.NaN\n",
    "            for _, row in df.iterrows():\n",
    "                values[partitions[0][1][row[partition_keys[0]]], \n",
    "                       partitions[1][1][row[partition_keys[1]]], \n",
    "                       partitions[2][1][row[partition_keys[2]]]] = row['value']\n",
    "        \n",
    "        max_value = np.nanmax(values)\n",
    "        values = np.nan_to_num(values, copy=False, nan=max_value + 1e-12) # set NaNs to just over the max value\n",
    "        \n",
    "        # trim data to the visible range\n",
    "        z_start = next((z for z in range(values.shape[2]) if np.any(values[:,:,z] < max_value)), 0)\n",
    "        z_end = next((z for z in reversed(range(values.shape[2])) if np.any(values[:,:,z] < max_value))\n",
    "                     , values.shape[2])\n",
    "        values = values[:,:,z_start:z_end+1]\n",
    "        z_index = z_index[z_start:z_end+1]\n",
    "            \n",
    "        print(f'value: {np.nanmin(values)} {np.nanmax(values)} z_start {z_start} z_end {z_end}')\n",
    "        mesh = [dim.flatten() for dim in np.meshgrid(\n",
    "            np.array(range(len(partitions[0][2]))),\n",
    "            np.array(range(len(partitions[1][2]))),\n",
    "            z_index,            \n",
    "            indexing='ij'\n",
    "            )]\n",
    "        print(f'{np.min(mesh[0])} {np.max(mesh[0])} {np.min(mesh[1])} {np.max(mesh[1])} {np.min(mesh[2])} {np.max(mesh[2])}')\n",
    "        fig = go.Figure(data=go.Volume(\n",
    "            x=mesh[0],\n",
    "            y=mesh[1],\n",
    "            z=mesh[2],\n",
    "            value=values.flatten(),\n",
    "            opacity=1.0,\n",
    "            isomin= np.nanmin(values),\n",
    "            isomax= max_value - 1e-12,\n",
    "            caps= dict(x_show=False, y_show=False, z_show=False),\n",
    "            surface_count=5,\n",
    "            opacityscale=\"min\",\n",
    "            colorscale=\"YlOrRd_r\"\n",
    "            ))\n",
    "        \n",
    "        print(z_index[0], z_index[-1])\n",
    "\n",
    "        axis_data = [dict(ticktext=p[2],\n",
    "                         tickvals=list(range(len(p[2]))),\n",
    "                         title=p[0]) \n",
    "                     for p in partitions]\n",
    "\n",
    "        fig.update_layout(\n",
    "            scene = dict(\n",
    "                xaxis = axis_data[0],\n",
    "                yaxis = axis_data[1],\n",
    "                zaxis = dict(\n",
    "                    nticks = 10,\n",
    "                    range=[z_index[0], z_index[-1]],\n",
    "                    title=epoch_axis\n",
    "                )\n",
    "            ),\n",
    "            width=950, height=950,\n",
    "            title=f\"{value_label} using {loss} for {dataset}, {topology}, residual {residual_mode}\",\n",
    "            )\n",
    "        return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43e2bdee8f0480796c594ffd37b938b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value=\"('fixed_01')\", description='groups'), Dropdown(description='dataset', index=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual(**options, viz=[\"volume\", \"scatter\"])\n",
    "def heatmap_app_3d(groups=\"('fixed_01')\", dataset=\"201_pol\", topology=\"trapezoid\", loss=\"history_val_loss\", agg=\"avg\", residual_mode=\"none\", viz=\"volume\", epoch_axis = 'epoch', color_range=1.25):\n",
    "    query_string = f'''\n",
    "    select \"config.budget\", \"config.depth\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "    from\n",
    "        materialized_experiments_0 t,\n",
    "        unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "    WHERE\n",
    "        \"groupname\" IN {groups} and\n",
    "        \"config.dataset\"='{dataset}' and\n",
    "        \"config.topology\"='{topology}' and\n",
    "        \"config.residual_mode\"='{residual_mode}'\n",
    "    GROUP BY epoch, \"config.budget\", \"config.depth\"\n",
    "    ORDER BY epoch, \"config.budget\", \"config.depth\"\n",
    "    '''\n",
    "    df = cached_query(query_string).query(\"count >= 7\")    \n",
    "    value_label, minimizing, best = setup_value(df, loss, color_range)    \n",
    "    if 'effort' in epoch_axis:\n",
    "        compute_effort(df)        \n",
    "    \n",
    "    if viz==\"scatter\":        \n",
    "        return px.scatter_3d(df,\n",
    "                    x='config.depth',\n",
    "                    y='config.budget',\n",
    "                    z=epoch_axis,\n",
    "                    color='value',\n",
    "                    log_y=True,\n",
    "                    opacity=0.25)\n",
    "    elif viz == \"volume\":\n",
    "        x_res = 2000\n",
    "        partition_keys = ['config.budget', 'config.depth']\n",
    "        \n",
    "        if 'effort' in epoch_axis:\n",
    "            partitions, z_index, values = partitioned_interpolation(df, partition_keys, epoch_axis, 'value', x_res)\n",
    "        else:\n",
    "            partition_keys.append(epoch_axis)\n",
    "            partitions = get_values_for_categorical_keys(df, partition_keys)\n",
    "            z_index = np.array(list(partitions[2][1].keys()))\n",
    "            values = np.empty((len(partitions[0][2]), len(partitions[1][2]), len(partitions[2][2])))\n",
    "            values[:] = np.NaN\n",
    "            for _, row in df.iterrows():\n",
    "                values[partitions[0][1][row[partition_keys[0]]], \n",
    "                       partitions[1][1][row[partition_keys[1]]], \n",
    "                       partitions[2][1][row[partition_keys[2]]]] = row['value']\n",
    "        \n",
    "        max_value = np.nanmax(values)\n",
    "        values = np.nan_to_num(values, copy=False, nan=max_value + 1e-12) # set NaNs to just over the max value\n",
    "        \n",
    "        # trim data to the visible range\n",
    "        z_start = next((z for z in range(values.shape[2]) if np.any(values[:,:,z] < max_value)), 0)\n",
    "        z_end = next((z for z in reversed(range(values.shape[2])) if np.any(values[:,:,z] < max_value))\n",
    "                     , values.shape[2])\n",
    "        values = values[:,:,z_start:z_end+1]\n",
    "        z_index = z_index[z_start:z_end+1]\n",
    "            \n",
    "        print(f'value: {np.nanmin(values)} {np.nanmax(values)} z_start {z_start} z_end {z_end}')\n",
    "        mesh = [dim.flatten() for dim in np.meshgrid(\n",
    "            np.array(range(len(partitions[0][2]))),\n",
    "            np.array(range(len(partitions[1][2]))),\n",
    "            z_index,            \n",
    "            indexing='ij'\n",
    "            )]\n",
    "        print(f'{np.min(mesh[0])} {np.max(mesh[0])} {np.min(mesh[1])} {np.max(mesh[1])} {np.min(mesh[2])} {np.max(mesh[2])}')\n",
    "        fig = go.Figure(data=go.Volume(\n",
    "            x=mesh[0],\n",
    "            y=mesh[1],\n",
    "            z=mesh[2],\n",
    "            value=values.flatten(),\n",
    "            opacity=1.0,\n",
    "            isomin= np.nanmin(values),\n",
    "            isomax= max_value - 1e-12,\n",
    "            caps= dict(x_show=False, y_show=False, z_show=False),\n",
    "            surface_count=5,\n",
    "            opacityscale=\"min\",\n",
    "            colorscale=\"YlOrRd_r\"\n",
    "            ))\n",
    "        \n",
    "        print(z_index[0], z_index[-1])\n",
    "\n",
    "        axis_data = [dict(ticktext=p[2],\n",
    "                         tickvals=list(range(len(p[2]))),\n",
    "                         title=p[0]) \n",
    "                     for p in partitions]\n",
    "\n",
    "        fig.update_layout(\n",
    "            scene = dict(\n",
    "                xaxis = axis_data[0],\n",
    "                yaxis = axis_data[1],\n",
    "                zaxis = dict(\n",
    "                    nticks = 10,\n",
    "                    range=[z_index[0], z_index[-1]],\n",
    "                    title=epoch_axis\n",
    "                )\n",
    "            ),\n",
    "            width=950, height=950,\n",
    "            title=f\"{value_label} using {loss} for {dataset}, {topology}, residual {residual_mode}\",\n",
    "            )\n",
    "        return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7926433dba3449959f13003dfbf990be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value=\"('fixed_01')\", description='groups'), Dropdown(description='dataset', index=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual(**options, \n",
    "                 statistic=[\"epoch\", \"effort\", \"log_effort\", 'relative_effort', 'relative_log_effort', 'relative_log_effort_to_minimize', 'best'], \n",
    "                 viz=['imshow', 'depth_lines', 'budget_lines'],\n",
    "                 depths=widgets.IntRangeSlider(min=2, max=20, step=1, value=(2,20)))\n",
    "def heatmap_app(groups=\"('fixed_01')\", dataset=\"201_pol\", topology=\"trapezoid\", loss=\"history_val_loss\", agg=\"avg\", residual_mode=\"none\", statistic = 'relative_log_effort', color_range=1.10, viz='imshow'):\n",
    "    query_string = f'''\n",
    "    select \"config.budget\", \"config.depth\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "    from\n",
    "        materialized_experiments_0 t,\n",
    "        unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "    WHERE\n",
    "        \"groupname\" IN {groups} and\n",
    "        \"config.dataset\"='{dataset}' and\n",
    "        \"config.topology\"='{topology}' and\n",
    "        \"config.residual_mode\"='{residual_mode}'\n",
    "    GROUP BY epoch, \"config.budget\", \"config.depth\"\n",
    "    ORDER BY epoch, \"config.budget\", \"config.depth\"\n",
    "    '''\n",
    "    df = cached_query(query_string).query(\"count >= 7\")    \n",
    "#     z_label, minimizing, best = setup_value(df, loss, color_range)    \n",
    "        \n",
    "#     if viz==\"efficiency\":        \n",
    "#         z_label = setup_value(df, loss, color_range)\n",
    "    partition_keys = ['config.depth', 'config.budget']\n",
    "    partitions = get_values_for_categorical_keys(df, partition_keys)\n",
    "    \n",
    "    filtered = df\n",
    "    if statistic != 'relative_log_effort_to_minimize':\n",
    "        best = np.nanmin(filtered['value']) # find best value\n",
    "        threshold = best * color_range\n",
    "        filtered = filtered[filtered['value'] <= threshold]\n",
    "            \n",
    "    minimize = 'epoch'\n",
    "    select = 'epoch'\n",
    "    if statistic == 'relative_log_effort_to_minimize':\n",
    "        minimize = 'value'\n",
    "    elif statistic == 'best':\n",
    "        minimize = 'value'\n",
    "        select = 'value'\n",
    "\n",
    "    def find_first_epoch(group):\n",
    "        return group.sort_values(minimize).iloc[0][select]\n",
    "\n",
    "    composite = filtered.groupby(partition_keys).apply(find_first_epoch).reset_index(name=select)\n",
    "\n",
    "    z_label = statistic\n",
    "    if statistic == 'best':\n",
    "        z_label, minimizing, best = setup_value(composite, loss, color_range)\n",
    "        composite[statistic] = composite[select] / np.min(composite[select])\n",
    "    else:\n",
    "        compute_effort(composite)\n",
    "        if statistic == 'relative_log_effort_to_minimize':\n",
    "            composite['relative_log_effort_to_minimize'] = composite['relative_log_effort']\n",
    "    \n",
    "    color_continuous_scale = 'Greens_r'\n",
    "    if statistic in ['epoch']:\n",
    "        color_continuous_scale = 'Sunsetdark'\n",
    "\n",
    "    if viz == 'imshow':\n",
    "        x_key = 'config.depth'\n",
    "        y_key = 'config.budget'\n",
    "        img = composite.pivot_table(columns=x_key, index=y_key, values=statistic)\n",
    "        fig = px.imshow(img, color_continuous_scale=color_continuous_scale,\n",
    "                       labels=dict(x=x_key, y=y_key, color=z_label))\n",
    "        axis_data = [dict(\n",
    "            categoryorder='array',\n",
    "            categoryarray=p[2],\n",
    "            title=p[0],\n",
    "            type='category') \n",
    "            for p in partitions]    \n",
    "        fig.update_layout(\n",
    "            xaxis = axis_data[0],\n",
    "            yaxis = axis_data[1],\n",
    "            title=f'{dataset}, {topology}, residual {residual_mode}<br>{statistic} to reach {\"{:.2f}\".format(100*(color_range-1))}% of best {loss}',\n",
    "#             coloraxis=dict(\n",
    "#                 title=statistic\n",
    "#                 )\n",
    "            coloraxis_colorbar_x=.7,\n",
    "            )\n",
    "    elif viz == 'depth_lines':\n",
    "        fig = px.line(composite, x='config.budget', y=statistic, color='config.depth', log_x=True)\n",
    "        \n",
    "    elif viz == 'budget_lines':\n",
    "        fig = px.line(composite, x='config.depth', y=statistic, color='config.budget')\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Heatmap App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d27aa99d9194dd2ab8ed9b1b1ca6d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value=\"('fixed_01')\", description='groups'), Dropdown(description='dataset', option…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual(**options, \n",
    "                 viz=[\"imshow\", \"scatter\", \"effort\"], \n",
    "                 depths=widgets.IntRangeSlider(min=2, max=20, step=1, value=(2,20)))\n",
    "def heatmap_app(\n",
    "    groups=\"('fixed_01')\", \n",
    "    dataset=\"529_pollen\", \n",
    "    topology=\"wide_first\", \n",
    "    loss=\"history_val_loss\", \n",
    "    agg=\"avg\",\n",
    "    residual_mode=\"none\", \n",
    "    viz=\"effort\", \n",
    "    depths=(2,20),\n",
    "    color_range=1.3):\n",
    "    \n",
    "    query_string = f'''\n",
    "select \"config.budget\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}' and\n",
    "    \"config.depth\" BETWEEN {depths[0]} and {depths[1]}\n",
    "GROUP BY epoch, \"config.budget\"\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    return make_2d_heatmap_viz(df, groups, dataset, topology, loss, agg, residual_mode, viz, color_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5db15a5efae4e1c86a171a1298372bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value=\"('fixed_01')\", description='groups'), Dropdown(description='dataset', option…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual(**options, \n",
    "                 viz=[\"imshow\", \"scatter\", \"effort\"])\n",
    "def heatmap_app(\n",
    "    groups=\"('fixed_01')\", \n",
    "    dataset=\"529_pollen\", \n",
    "    topology=\"wide_first\", \n",
    "    loss=\"history_val_loss\", \n",
    "    agg=\"avg\",\n",
    "    residual_mode=\"none\", \n",
    "    viz=\"effort\", \n",
    "    depth=3,\n",
    "    color_range=4.0):\n",
    "    \n",
    "    query_string = f'''\n",
    "select \"config.budget\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}' and\n",
    "    \"config.depth\" = {depth}\n",
    "GROUP BY epoch, \"config.budget\"\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    return make_2d_heatmap_viz(df, groups, dataset, topology, loss, agg, residual_mode, viz, color_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db935bac21284a73a3101c5dce29c9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value=\"('fixed_01')\", description='groups'), Dropdown(description='dataset', index=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual(**options, \n",
    "                 viz=[\"imshow\", \"scatter\", \"effort\"], \n",
    "                 depths=widgets.IntRangeSlider(min=2, max=20, step=1, value=(2,20)))\n",
    "def heatmap_app(\n",
    "    groups=\"('fixed_01')\", \n",
    "    dataset=\"sleep\", \n",
    "    topology=\"rectangular\", \n",
    "    loss=\"history_val_loss\", \n",
    "    agg=\"avg\",\n",
    "    group_select=\"min\",\n",
    "    residual_mode=\"none\", \n",
    "    viz=\"effort\", \n",
    "    depths=(2,20),\n",
    "    color_range=1.25):    \n",
    "    group_direction = 'asc' if group_select == 'min' else 'desc'        \n",
    "    query_string = f'''\n",
    "SELECT min_groups.\"config.budget\", min_groups.\"config.depth\", count(*), {agg}(a.value) AS value, a.epoch as epoch\n",
    "FROM\n",
    "    (SELECT \"config.budget\", \"config.depth\"\n",
    "     FROM\n",
    "        (SELECT \"config.budget\", \"config.depth\",\n",
    "               ROW_NUMBER() OVER(PARTITION BY min_values.\"config.budget\" ORDER BY {agg}(min_value) {group_direction}) AS rank\n",
    "        FROM\n",
    "            (SELECT \"config.budget\", \"config.depth\", t.id AS id, {group_select}(a.val) AS min_value\n",
    "            FROM\n",
    "                materialized_experiments_0 t,\n",
    "                unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "            WHERE\n",
    "             t.\"groupname\" IN {groups} and\n",
    "             t.\"config.dataset\"='{dataset}' and\n",
    "             t.\"config.topology\"='{topology}' and\n",
    "             t.\"config.residual_mode\"='{residual_mode}' and\n",
    "             t.\"config.depth\" BETWEEN {depths[0]} and {depths[1]}\n",
    "            GROUP BY \"config.budget\", \"config.depth\", t.id) AS min_values\n",
    "        GROUP BY \"config.budget\", \"config.depth\") AS min_groups\n",
    "        WHERE rank = 1) as min_groups,\n",
    "    materialized_experiments_0 as t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(value, epoch)\n",
    "WHERE\n",
    "    min_groups.\"config.budget\" = t.\"config.budget\" AND\n",
    "    min_groups.\"config.depth\" = t.\"config.depth\" AND\n",
    "    t.\"groupname\" IN {groups} and\n",
    "    t.\"config.dataset\"='{dataset}' and\n",
    "    t.\"config.topology\"='{topology}' and\n",
    "    t.\"config.residual_mode\"='{residual_mode}' and\n",
    "    t.\"config.depth\" BETWEEN {depths[0]} and {depths[1]}\n",
    "GROUP BY min_groups.\"config.budget\", min_groups.\"config.depth\", a.epoch;\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    fig = make_2d_heatmap_viz(df, groups, dataset, topology, loss, agg, residual_mode, viz, color_range)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178926e18d2a4a6a943358badaf3461e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value=\"('fixed_01')\", description='groups'), Dropdown(description='dataset', option…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual(**options, \n",
    "                 viz=[\"imshow\", \"scatter\", \"effort\"], \n",
    "                 depths=widgets.IntRangeSlider(min=2, max=20, step=1, value=(2,20)))\n",
    "def heatmap_app(\n",
    "    groups=\"('fixed_01')\", \n",
    "    dataset=\"529_pollen\", \n",
    "    topology=\"wide_first\", \n",
    "    loss=\"history_val_loss\", \n",
    "    agg=\"avg\",\n",
    "    group_select=\"min\",\n",
    "    residual_mode=\"none\", \n",
    "    viz=\"effort\", \n",
    "    depths=(2,20),\n",
    "    color_range=4.0):    \n",
    "    group_direction = 'asc' if group_select == 'min' else 'desc'        \n",
    "    query_string = f'''\n",
    "SELECT min_groups.\"config.budget\", min_groups.\"config.depth\", count(*), {agg}(a.value) AS value, a.epoch as epoch\n",
    "FROM\n",
    "    (SELECT \"config.budget\", \"config.depth\"\n",
    "     FROM\n",
    "        (SELECT \"config.budget\", \"config.depth\",\n",
    "               ROW_NUMBER() OVER(PARTITION BY min_values.\"config.budget\" ORDER BY {agg}(min_value) {group_direction}) AS rank\n",
    "        FROM\n",
    "            (SELECT \"config.budget\", \"config.depth\", t.id AS id, {group_select}(a.val) AS min_value\n",
    "            FROM\n",
    "                materialized_experiments_0 t,\n",
    "                unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "            WHERE\n",
    "             t.\"groupname\" IN {groups} and\n",
    "             t.\"config.dataset\"='{dataset}' and\n",
    "             t.\"config.topology\"='{topology}' and\n",
    "             t.\"config.residual_mode\"='{residual_mode}' and\n",
    "             t.\"config.depth\" BETWEEN {depths[0]} and {depths[1]}\n",
    "            GROUP BY \"config.budget\", \"config.depth\", t.id) AS min_values\n",
    "        GROUP BY \"config.budget\", \"config.depth\") AS min_groups\n",
    "        WHERE rank = 1) as min_groups,\n",
    "    materialized_experiments_0 as t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(value, epoch)\n",
    "WHERE\n",
    "    min_groups.\"config.budget\" = t.\"config.budget\" AND\n",
    "    min_groups.\"config.depth\" = t.\"config.depth\" AND\n",
    "    t.\"groupname\" IN {groups} and\n",
    "    t.\"config.dataset\"='{dataset}' and\n",
    "    t.\"config.topology\"='{topology}' and\n",
    "    t.\"config.residual_mode\"='{residual_mode}' and\n",
    "    t.\"config.depth\" BETWEEN {depths[0]} and {depths[1]}\n",
    "GROUP BY min_groups.\"config.budget\", min_groups.\"config.depth\", a.epoch;\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    return make_2d_heatmap_viz(df, groups, dataset, topology, loss, agg, residual_mode, viz, color_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c08c0f84bd49f18d98d890a83e9a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value=\"('fixed_01')\", description='groups'), Dropdown(description='dataset', index=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# what depth is best for a given budget and toplogy?\n",
    "\n",
    "@interact_manual(**options, \n",
    "                 viz=[\"imshow\", \"scatter\", \"effort\"])\n",
    "def heatmap_app(\n",
    "    groups=\"('fixed_01')\", \n",
    "    dataset=\"201_pol\", \n",
    "    topology=\"trapezoid\", \n",
    "    loss=\"history_val_loss\", \n",
    "    agg=\"avg\",\n",
    "    residual_mode=\"none\", \n",
    "    viz=\"effort\", \n",
    "    budget=8192,\n",
    "    color_range=1.1):\n",
    "    \n",
    "    query_string = f'''\n",
    "select \"config.depth\", \"config.budget\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}' and\n",
    "    \"config.budget\" = {budget}\n",
    "GROUP BY \"config.depth\", \"config.budget\", epoch\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    \n",
    "    \n",
    "    z_label = setup_value(df, loss, color_range)\n",
    "    x_key = 'epoch'\n",
    "    y_key = 'config.depth'\n",
    "    img = df.pivot_table(columns=\"epoch\", index=\"config.depth\", values=\"value\")\n",
    "    img.index = img.index.astype(\"str\") #plotly interprets the y axis as numeric otherwise\n",
    "    fig = px.imshow(img)\n",
    "    fig.update_yaxes(type='category')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot a line for each depth across budgets for a specific topology - best value? \n",
    "# plot a line for each topology across budgets for a specific depth, or the best depth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Your Axis Heatmap Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece70a94f47f4e9783a42faccd89f4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value=\"('fixed_01')\", description='groups'), Text(value='epoch', description='x_dim…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "axis = [\"dataset\", \"topology\", \"residual_mode\", \"budget\"]\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"], y_dim=axis)\n",
    "def heatmap_app(groups=\"('fixed_01')\", x_dim=\"epoch\", y_dim=\"budget\", budget=\"64\", dataset=\"537_houses\", topology=\"wide_first\", loss=\"history_val_mean_squared_error\", agg=\"avg\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    axis = [\"dataset\", \"topology\", \"residual_mode\", \"budget\"]\n",
    "    args = locals()\n",
    "    filter_string = \" and \".join([f'''\"config.{s}\"='{args[s]}' ''' for s in axis if s != y_dim])\n",
    "    query_string = f'''\n",
    "select \"config.{y_dim}\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    {filter_string}\n",
    "GROUP BY {x_dim}, \"config.{y_dim}\"\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    \n",
    "    if viz == \"imshow\":\n",
    "        #df = df.query(\"count > 389\")\n",
    "        img = df.pivot_table(columns=x_dim, index=\"config.\"+y_dim, values=\"value\")\n",
    "        img.index = img.index.astype(\"str\") #plotly interprets the y axis as numeric otherwise\n",
    "        return px.imshow(img)\n",
    "    elif viz == \"scatter\":\n",
    "        df = df.sort_values([\"epoch\", \"config.budget\"], ascending=[True, False])\n",
    "        df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "        df[\"epoch\"] = df[\"epoch\"].astype(\"str\")\n",
    "        return px.scatter(df, x=\"epoch\", y=\"config.budget\", size=\"count\", color=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Plot for Single budget x dataset x topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### single run app\n",
    "\n",
    "@interact(**options)\n",
    "def heatmap_app(dataset=\"537_houses\", topology=\"wide_first\", loss=\"history_val_mean_squared_error\", agg=\"avg\", residual_mode=\"none\",\n",
    "               budget=\"256\"):\n",
    "    query_string = f'''\n",
    "select a.val as value, a.epoch, run_name\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN ('exp00', 'exp01') and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}' and\n",
    "    \"config.budget\"='{budget}'\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    return px.line(df, x=\"epoch\", y=\"value\", color=\"run_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "- 537 houses, (val) kl divergence, trapezoid\n",
    "- sleep, trapezoid, history_val_loss, 16777216\n",
    "\n",
    "Notes:\n",
    "- Logarithmic color map\n",
    "- look into why sleep runs crash for high budgets\n",
    "- plateau effect\n",
    "- review stopping configurations / what is reasonable number of iterations?\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "## Look at \"plateau\" feature from Charle's notebooks\n",
    "## Add dataset, dataset complexity, as axis\n",
    "## Add topology as an axis\n",
    "### learning rate / optimizers / other axis to add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To re-run using fixed epoch length, how long is reasonable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def heatmap_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    avg(array_length(t.history_loss, 1)) as avg,\n",
    "    min(array_length(t.history_loss, 1)) as min,\n",
    "    max(array_length(t.history_loss, 1)) as max,\n",
    "    stddev(array_length(t.history_loss, 1)) as std\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "GROUP BY \"config.budget\"\n",
    "'''\n",
    "    df = cached_query(query_string).sort_values(\"config.budget\")\n",
    "    \n",
    "    return px.line(df, x=\"config.budget\", y=\"avg\", error_y=\"std\", log_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Epoch Count App\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def epoch_count_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    array_length(t.history_loss, 1) as num_epochs\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    df = df.sort_values(\"config.budget\")\n",
    "    df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "    \n",
    "    return px.scatter(df, x=\"config.budget\", y=\"num_epochs\", title=f\"Number of epochs for {dataset}, {topology} in {groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Epoch Count App\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def epoch_count_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    \"config.topology\",\n",
    "    array_length(t.history_loss, 1) as num_epochs\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "'''\n",
    "    df = cached_query(query_string).sort_values(\"config.budget\")\n",
    "    \n",
    "    df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "    \n",
    "    return px.violin(df,\n",
    "                    x=\"config.budget\",\n",
    "                    y=\"num_epochs\",\n",
    "                    color=\"config.topology\",\n",
    "                     box=True,\n",
    "                    title=f\"Number of epochs for {dataset}, in {groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Epoch Count App\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def epoch_count_agg_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    \"config.dataset\",\n",
    "    array_length(t.history_loss, 1) as num_epochs\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "'''\n",
    "    df = cached_query(query_string).sort_values(\"config.budget\")\n",
    "    \n",
    "    df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "    \n",
    "    return px.violin(df,\n",
    "                    x=\"config.budget\",\n",
    "                    y=\"num_epochs\",\n",
    "                    color=\"config.dataset\",\n",
    "                     box=True,\n",
    "                    title=f\"Number of epochs for {topology}, in {groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate 90th percentile epoch length for each experiment\n",
    "query_string = f'''\n",
    "select\n",
    "    (percentile_disc(0.9) within group (order by array_length(t.history_loss, 1))) as epoch_90_pctile,\n",
    "    \"config.topology\",\n",
    "    \"config.residual_mode\",\n",
    "    \"config.dataset\",\n",
    "    \"config.budget\"\n",
    "FROM\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN ('exp00','exp01')\n",
    "GROUP BY\n",
    "    \"config.topology\",\n",
    "    \"config.residual_mode\",\n",
    "    \"config.dataset\",\n",
    "    \"config.budget\"\n",
    "'''\n",
    "\n",
    "df = cached_query(query_string)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate 90th percentile epoch length for each experiment\n",
    "query_string = f'''\n",
    "    select\n",
    "        max(array_length(t.history_loss, 1)) as epoch_max,\n",
    "        (percentile_disc(0.90) within group (order by array_length(t.history_loss, 1))) as epoch_90_pctile,\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\"\n",
    "    FROM\n",
    "        materialized_experiments_0 t\n",
    "    WHERE\n",
    "        \"groupname\" IN ('exp00','exp01')\n",
    "    GROUP BY\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\"\n",
    "'''\n",
    "\n",
    "df = cached_query(query_string)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby([\"config.topology\", \"config.residual_mode\", \"config.dataset\"]).max().drop(\"config.budget\", axis=1)\n",
    "\n",
    "df2.to_csv(\"epoch_90th_pctile.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"epoch_90th_pctile_each_budget.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, we want to add dataset (or some statistic derived from the dataset's complexity) and topology as axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cached_query('''select * from materialized_experiments_0 WHERE \"groupname\" IN ('exp04') limit 10''')\n",
    "display(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the heatmap of validation loss for one topology, one dataset, over iteration count and different budgets\n",
    "\n",
    "q = '''\n",
    "select \"config.budget\", avg(a.val) as val_loss, avg(a.loss) as train_loss, count(a.loss), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.history_val_mean_squared_error, t.history_mean_squared_error) WITH ORDINALITY as a(val, loss, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN ('exp00', 'exp01') and\n",
    "    \"config.dataset\"='537_houses' and\n",
    "    \"config.topology\"='wide_first' and\n",
    "    \"config.residual_mode\"='none'\n",
    "GROUP BY epoch, \"config.budget\"\n",
    "'''\n",
    "\n",
    "# q = '''\n",
    "# select distinct(\"name\")\n",
    "# from\n",
    "#     materialized_experiments_0\n",
    "# WHERE\n",
    "#     \"groupname\" IN ('exp00', 'exp01') and\n",
    "#     \"config.dataset\"='537_houses' and\n",
    "#     \"config.topology\"='wide_first' and\n",
    "#     \"config.residual_mode\"='none' and\n",
    "#     \"config.budget\"=262144\n",
    "# limit 10\n",
    "# '''\n",
    "\n",
    "df = cache_query(q)\n",
    "display(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate max of 95th percentile epoch length and iterations to smallest loss over all topologies for each budget and dataset\n",
    "query_string = f'''\n",
    "select max(max_iterations) as max_iterations,\n",
    "       max(p95) as p95,\n",
    "       max(p90) as p90,\n",
    "       max(p67) as p67,\n",
    "       max(p50) as p50,\n",
    "       max(p33) as p33,\n",
    "       max(avg_iterations) as avg_iterations,\n",
    "       max(foo.max_patience) as max_patience,\n",
    "       min(foo.min_patience) as min_patience,\n",
    "    foo.\"config.dataset\",\n",
    "    foo.\"config.budget\"\n",
    "--    foo.\"config.topology\",\n",
    "--    foo.\"config.residual_mode\"\n",
    "FROM\n",
    "    (SELECT\n",
    "        MAX(iterations) as max_iterations,\n",
    "        (percentile_disc(0.95) within group (order by iterations ASC)) as p95,\n",
    "        (percentile_disc(0.9) within group (order by iterations ASC)) as p90,\n",
    "        (percentile_disc(0.67) within group (order by iterations ASC)) as p67,\n",
    "        (percentile_disc(0.5) within group (order by iterations ASC)) as p50,\n",
    "        (percentile_disc(0.33) within group (order by iterations ASC)) as p33,\n",
    "        AVG(iterations) as avg_iterations,\n",
    "        max(\"config.early_stopping.patience\") as max_patience,\n",
    "        min(\"config.early_stopping.patience\") as min_patience,\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\",\n",
    "        \"config.depth\"\n",
    "    FROM\n",
    "        materialized_experiments_0 t\n",
    "    WHERE\n",
    "        \"groupname\" IN ('exp00','exp01')\n",
    "    GROUP BY\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\",\n",
    "        \"config.depth\") AS foo\n",
    "    GROUP BY\n",
    "        foo.\"config.dataset\",\n",
    "        foo.\"config.budget\"\n",
    "--        foo.\"config.topology\",\n",
    "--        foo.\"config.residual_mode\"\n",
    "'''\n",
    "\n",
    "df = cached_query(query_string)\n",
    "display(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df['config.dataset']))\n",
    "# print(pd.unique(df['config.topology']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'connect_4'\n",
    "filtered = df[df['config.dataset'] == dataset]\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(filtered['config.budget'], filtered['max_iterations'], 'ok-', label='max_iterations')\n",
    "ax.plot(filtered['config.budget'], filtered['p95'], 'or-', label='p95')\n",
    "ax.plot(filtered['config.budget'], filtered['p90'], 'ob', label='p90')\n",
    "ax.plot(filtered['config.budget'], filtered['p67'], 'ob', label='p67')\n",
    "ax.plot(filtered['config.budget'], filtered['p50'], 'og-', label='p50')\n",
    "ax.plot(filtered['config.budget'], filtered['p33'], 'ob', label='p33')\n",
    "ax.plot(filtered['config.budget'], filtered['avg_iterations'], 'o-k', label='avg_percentile')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.legend()\n",
    "ax.set_xlabel('budget')\n",
    "ax.set_ylabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasets = [d for d in pd.unique(df['config.dataset']) if d not in {'nursery', 'adult'}]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for dataset in datasets:\n",
    "#     if dataset != '529_pollen':\n",
    "#         continue\n",
    "#     filtered = df[(df['config.dataset'] == dataset) & (df['config.topology'] == 'trapezoid') & (df['config.residual_mode'] == 'none')]\n",
    "    filtered = df[(df['config.dataset'] == dataset)]\n",
    "    budget = filtered['config.budget']\n",
    "    v = filtered['p95']\n",
    "#     v = np.log10(v)\n",
    "#     v_min = v.min()\n",
    "#     v_max = v.max()\n",
    "#     v_avg = v.mean()\n",
    "#     v_std = v.std()\n",
    "#     v_norm = (v - v_avg) / (v_std)\n",
    "#     ax.plot(budget, v, 'o-', label=dataset)\n",
    "    ax.plot(budget, v, 'o-', label=dataset)\n",
    "    print(filtered[filtered['config.budget'] == 8192]['p95'].iloc[0])\n",
    "    \n",
    "#     ax.plot(budget, budget * filtered[], 'o-', label=dataset)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('budget')\n",
    "    ax.set_ylabel('epochs / budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "for dataset in datasets:\n",
    "    filtered = df[(df['config.dataset'] == dataset)]\n",
    "    budget = filtered['config.budget']\n",
    "    v = filtered['p95']\n",
    "    x = np.log(budget)\n",
    "    y = np.log(v/budget)\n",
    "    X = np.reshape(x.to_numpy(), (len(x), 1))\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    print(f'{dataset} score: {reg.score(X, y)} coef: {reg.coef_} intercept: {reg.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def fit_above(x, y) :\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    x0, y0 = x[0] - 1, y[0]\n",
    "    x -= x0\n",
    "    y -= y0\n",
    "\n",
    "    def error_function_2(b, x, y) :\n",
    "        a = np.max((y - b) / x)\n",
    "        return np.sum((y - a * x - b)**2)\n",
    "\n",
    "    b = scipy.optimize.minimize(error_function_2, [0], args=(x, y)).x[0]\n",
    "\n",
    "    a = np.max((y - b) / x)\n",
    "\n",
    "    return a, b - a * x0 + y0\n",
    "\n",
    "datasets = [d for d in pd.unique(df['config.dataset']) if d not in {'nursery', 'adult'}]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for dataset in datasets:\n",
    "#     if dataset != '529_pollen':\n",
    "#         continue\n",
    "#     filtered = df[(df['config.dataset'] == dataset) & (df['config.topology'] == 'trapezoid') & (df['config.residual_mode'] == 'none')]\n",
    "    filtered = df[(df['config.dataset'] == dataset)]\n",
    "    budget = filtered['config.budget'].to_numpy()\n",
    "    v = filtered['avg_iterations'].to_numpy()\n",
    "    x = np.log(budget)\n",
    "#     x = 1.0 / budget\n",
    "#     y = np.log(v)\n",
    "#     y = np.log(v)\n",
    "    y = np.log(v)\n",
    "#     v = np.log10(v)\n",
    "#     v_min = v.min()\n",
    "#     v_max = v.max()\n",
    "#     v_avg = v.mean()\n",
    "#     v_std = v.std()\n",
    "#     v_norm = (v - v_avg) / (v_std)\n",
    "#     ax.plot(budget, v, 'o-', label=dataset)\n",
    "    p = ax.plot(x, y, 'o-', label=dataset)\n",
    "    \n",
    "#     X = np.reshape(x, (len(x), 1))\n",
    "#     reg = LinearRegression().fit(X, y)\n",
    "#     print(f'{dataset} score: {reg.score(X, y)} coef: {reg.coef_} intercept: {reg.intercept_}')\n",
    "    \n",
    "#     ax.plot(x, y, 'o-', label=dataset)\n",
    "#     ax.plot(x, reg.coef_ * x + reg.intercept_, '-', color = p[0].get_color())\n",
    "    \n",
    "    m, b = fit_above(x,y)\n",
    "    extra = .5\n",
    "    b+=extra\n",
    "    plt.plot(x, m*x + b, '-', color=p[0].get_color())\n",
    "    print(f'{dataset} m: {m} b: {b}')\n",
    "#     ax.plot(budget, budget * filtered[], 'o-', label=dataset)\n",
    "\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('log(budget)')\n",
    "    ax.set_ylabel('log(95th percentile epochs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def fit_above(x, y) :\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    x0, y0 = x[0] - 1, y[0]\n",
    "    x -= x0\n",
    "    y -= y0\n",
    "\n",
    "    def error_function_2(b, x, y) :\n",
    "        a = np.max((y - b) / x)\n",
    "        return np.sum((y - a * x - b)**2)\n",
    "\n",
    "    b = scipy.optimize.minimize(error_function_2, [0], args=(x, y)).x[0]\n",
    "\n",
    "    a = np.max((y - b) / x)\n",
    "\n",
    "    return a, b - a * x0 + y0\n",
    "\n",
    "datasets = [d for d in pd.unique(df['config.dataset']) if d not in {'nursery', 'adult'}]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for dataset in datasets:\n",
    "#     if dataset != '529_pollen':\n",
    "#         continue\n",
    "#     filtered = df[(df['config.dataset'] == dataset) & (df['config.topology'] == 'trapezoid') & (df['config.residual_mode'] == 'none')]\n",
    "    filtered = df[(df['config.dataset'] == dataset)]\n",
    "    budget = filtered['config.budget'].to_numpy()\n",
    "    v = filtered['avg_iterations'].to_numpy()\n",
    "    x = np.log(budget)\n",
    "#     x = 1.0 / budget\n",
    "#     y = np.log(v)\n",
    "#     y = np.log(v)\n",
    "    y = np.log(v)\n",
    "#     v = np.log10(v)\n",
    "#     v_min = v.min()\n",
    "#     v_max = v.max()\n",
    "#     v_avg = v.mean()\n",
    "#     v_std = v.std()\n",
    "#     v_norm = (v - v_avg) / (v_std)\n",
    "#     ax.plot(budget, v, 'o-', label=dataset)\n",
    "#     p = ax.plot(x, y, 'o-', label=dataset)\n",
    "    \n",
    "#     X = np.reshape(x, (len(x), 1))\n",
    "#     reg = LinearRegression().fit(X, y)\n",
    "#     print(f'{dataset} score: {reg.score(X, y)} coef: {reg.coef_} intercept: {reg.intercept_}')\n",
    "    \n",
    "#     ax.plot(x, y, 'o-', label=dataset)\n",
    "#     ax.plot(x, reg.coef_ * x + reg.intercept_, '-', color = p[0].get_color())\n",
    "    \n",
    "    m, b = fit_above(x,y)\n",
    "    extra = .1\n",
    "    b+=extra\n",
    "#     plt.plot(x, m*x + b, '-', color=p[0].get_color())\n",
    "    print(f'{dataset} m: {m} b: {b}')\n",
    "#     ax.plot(budget, budget * filtered[], 'o-', label=dataset)\n",
    "    bound = np.ceil(np.exp(m * np.log(budget) + b))\n",
    "    p = ax.plot(x, bound/v , 'o-', label=dataset)\n",
    "    print(f'dataset {dataset} {bound}')\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('budget')\n",
    "    ax.set_ylabel('epochs / budget')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [d for d in pd.unique(df['config.dataset']) if d not in {'nursery', 'adult'}]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for dataset in datasets:\n",
    "#     if dataset != '529_pollen':\n",
    "#         continue\n",
    "#     filtered = df[(df['config.dataset'] == dataset) & (df['config.topology'] == 'trapezoid') & (df['config.residual_mode'] == 'none')]\n",
    "    filtered = df[(df['config.dataset'] == dataset)]\n",
    "    budget = filtered['config.budget']\n",
    "    v = filtered['p95']\n",
    "#     v = np.log10(v)\n",
    "#     v_min = v.min()\n",
    "#     v_max = v.max()\n",
    "#     v_avg = v.mean()\n",
    "#     v_std = v.std()\n",
    "#     v_norm = (v - v_avg) / (v_std)\n",
    "#     ax.plot(budget, v, 'o-', label=dataset)\n",
    "    ax.plot(budget, v, 'o-', label=dataset)\n",
    "    print(filtered[filtered['config.budget'] == 8192]['p95'].iloc[0])\n",
    "    \n",
    "#     ax.plot(budget, budget * filtered[], 'o-', label=dataset)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('budget')\n",
    "#     ax.set_ylabel('epochs / budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = f'''\n",
    "    SELECT\n",
    "        MAX(iterations) as max_iterations,\n",
    "        (percentile_disc(0.95) within group (order by iterations ASC)) as p95,\n",
    "        (percentile_disc(0.9) within group (order by iterations ASC)) as p90,\n",
    "        (percentile_disc(0.67) within group (order by iterations ASC)) as p67,\n",
    "        (percentile_disc(0.5) within group (order by iterations ASC)) as p50,\n",
    "        (percentile_disc(0.33) within group (order by iterations ASC)) as p33,\n",
    "        AVG(iterations) as avg_percentile,\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\",\n",
    "        max(\"config.early_stopping.patience\") as max_patience,\n",
    "        min(\"config.early_stopping.patience\") as min_patience,\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\"\n",
    "    FROM\n",
    "        materialized_experiments_0 t\n",
    "    WHERE\n",
    "        \"groupname\" IN ('exp00','exp01','exp02','exp05','exp06')\n",
    "    GROUP BY\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\"\n",
    "'''\n",
    "\n",
    "df = cached_query(query_string)\n",
    "display(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [d for d in pd.unique(df['config.dataset']) if d not in {'nursery', 'adult'}]\n",
    "\n",
    "styles = ['']\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for dataset in datasets:\n",
    "    f1 = df[df['config.dataset'] == dataset]\n",
    "    for topology in pd.unique(f1['config.topology']):\n",
    "        filtered = f1[f1['config.topology'] == topology]\n",
    "        v = filtered['p95']\n",
    "        v = np.log(v)\n",
    "        v_min = v.min()\n",
    "        v_max = v.max()\n",
    "        v_avg = v.mean()\n",
    "        v_std = v.std()\n",
    "        v_norm = (v - v_avg) / (v_std)\n",
    "        ax.plot(filtered['config.budget'], v_norm, 'o', label=f'{dataset} {topology}')\n",
    "\n",
    "    #     ax.set_yscale('log')\n",
    "        ax.set_xscale('log')\n",
    "#         ax.legend()\n",
    "        ax.set_xlabel('budget')\n",
    "        ax.set_ylabel('normed epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
