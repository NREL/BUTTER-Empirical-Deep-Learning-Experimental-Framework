{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations in Plotly for the DMP Aspect Test Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from dmp.data.logging import _get_sql_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from joblib import Memory\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = _get_sql_engine()\n",
    "\n",
    "memory = Memory(location=\"./cache\", verbose=0)\n",
    "\n",
    "def query(query_string):\n",
    "    with db.connect() as engine:\n",
    "        return pd.read_sql(query_string, engine)\n",
    "\n",
    "cached_query = memory.cache(query)\n",
    "\n",
    "def clear_cache():\n",
    "    memory.clear()\n",
    "    \n",
    "options = {\n",
    "    \"dataset\": ['529_pollen',\n",
    "        'sleep',\n",
    "        'adult',\n",
    "        '537_houses',\n",
    "        'nursery',\n",
    "        '201_pol',\n",
    "        'mnist',\n",
    "        'connect_4',\n",
    "        'wine_quality_white'],\n",
    "    \"agg\": [\"avg\", \"min\", \"max\"],\n",
    "    \"topology\" : [\"exponential\", \"rectangle\", \"trapezoid\", \"wide_first\"],\n",
    "    \"loss\": ['history_loss', 'history_hinge', 'history_accuracy',\n",
    "       'history_val_loss', 'history_val_hinge', 'history_val_accuracy',\n",
    "       'history_squared_hinge', 'history_cosine_similarity',\n",
    "       'history_val_squared_hinge', 'history_mean_squared_error',\n",
    "       'history_mean_absolute_error', 'history_val_cosine_similarity',\n",
    "       'history_val_mean_squared_error', 'history_root_mean_squared_error',\n",
    "       'history_val_mean_absolute_error',\n",
    "       'history_kullback_leibler_divergence',\n",
    "       'history_val_root_mean_squared_error',\n",
    "       'history_mean_squared_logarithmic_error',\n",
    "       'history_val_kullback_leibler_divergence',\n",
    "       'history_val_mean_squared_logarithmic_error'],\n",
    "    \"residual_mode\": [\"none\", \"full\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[Memory(location=./cache/joblib)]: Flushing completely the cache\n"
     ]
    }
   ],
   "source": [
    "clear_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Heatmap App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23840df47674e8bbd2133e3721f1bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value=\"('fixed_01')\", description='groups'), Dropdown(description='dataset', optionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def heatmap_app_3d(groups=\"('fixed_01')\", dataset=\"529_pollen\", topology=\"rectangular\", loss=\"history_val_loss\", agg=\"avg\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "    select \"config.budget\", \"config.depth\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "    from\n",
    "        materialized_experiments_0 t,\n",
    "        unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "    WHERE\n",
    "        \"groupname\" IN {groups} and\n",
    "        \"config.dataset\"='{dataset}' and\n",
    "        \"config.topology\"='{topology}' and\n",
    "        \"config.residual_mode\"='{residual_mode}'\n",
    "    GROUP BY epoch, \"config.budget\", \"config.depth\"\n",
    "    ORDER BY epoch, \"config.budget\", \"config.depth\"\n",
    "    '''\n",
    "    df = cached_query(query_string).query(\"count >= 7\")\n",
    "    \n",
    "    if viz==\"scatter\":\n",
    "        \n",
    "        fig = px.scatter_3d(df,\n",
    "                    x='config.depth',\n",
    "                    y='config.budget',\n",
    "                    z='epoch',\n",
    "                    color='value',\n",
    "                    log_y=True,\n",
    "                    opacity=0.25)\n",
    "        fig.show()\n",
    "        \n",
    "    elif viz==\"imshow\":\n",
    "\n",
    "        dimensions = [\"config.budget\", \"config.depth\", \"epoch\"]\n",
    "\n",
    "        df[dimensions[0]] = df[dimensions[0]].astype(int)\n",
    "        df[dimensions[1]] = df[dimensions[1]].astype(int)\n",
    "        df[dimensions[2]] = df[dimensions[2]].astype(int)\n",
    "\n",
    "        x_labels, y_labels, z_labels = [sorted(df[dim].unique()) for dim in dimensions]\n",
    "        X, Y, Z = np.mgrid[0:len(x_labels), 0:len(y_labels), 0:len(z_labels)]\n",
    "        values = np.empty((X+Y+Z).shape)\n",
    "        values[:] = np.NaN\n",
    "\n",
    "        x_idx = {a:b for b,a in enumerate(x_labels)}\n",
    "        y_idx = {a:b for b,a in enumerate(y_labels)}\n",
    "        z_idx = {a:b for b,a in enumerate(z_labels)}\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            values[x_idx[row[dimensions[0]]], y_idx[row[dimensions[1]]], z_idx[row[dimensions[2]]]] = -np.log(row[\"value\"])\n",
    "\n",
    "        v_min = np.min(values)\n",
    "        v_max = np.max(values)\n",
    "        isomin = v_min + .2 * (v_max - v_min)\n",
    "        print(f'min {v_min} max {v_max} isomin {isomin}')\n",
    "        \n",
    "        print(f'x {X.flatten().shape} y {Y.flatten().shape} z {X.flatten().shape}')\n",
    "        fig = go.Figure(data=go.Volume(\n",
    "            x=X.flatten(),\n",
    "            y=Y.flatten(),\n",
    "            z=Z.flatten(),\n",
    "            value=values.flatten(),\n",
    "            opacity=0.2, # needs to be small to see through all surfaces\n",
    "            isomin= isomin,\n",
    "            isomax = v_max,\n",
    "            caps= dict(x_show=False, y_show=False, z_show=False),\n",
    "            surface_count=30\n",
    "            ))\n",
    "\n",
    "        fig.update_layout(scene = dict(\n",
    "                            xaxis = dict(ticktext=x_labels,\n",
    "                                         tickvals=list(range(0,len(x_labels))),\n",
    "                                         title=dimensions[0]),\n",
    "\n",
    "                            yaxis = dict(ticktext=y_labels,\n",
    "                                         tickvals=list(range(0,len(y_labels))),\n",
    "                                         title=dimensions[1]),\n",
    "\n",
    "                            zaxis = dict(ticktext=z_labels,\n",
    "                                         tickvals=list(range(0,len(z_labels))),\n",
    "                                         title=dimensions[2]),\n",
    "\n",
    "\n",
    "                            ),\n",
    "                            width=700, height=700,\n",
    "                            title=f\"{loss} for {dataset}, {topology}, residual {residual_mode}\")\n",
    "        fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Heatmap App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def heatmap_app(groups=\"('fixed_01')\", dataset=\"529_pollen\", topology=\"wide_first\", loss=\"history_val_loss\", agg=\"avg\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select \"config.budget\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "GROUP BY epoch, \"config.budget\"\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    \n",
    "    if viz == \"imshow\":\n",
    "        #df = df.query(\"count > 389\")\n",
    "        df[\"value\"] = np.log(np.minimum(df[\"value\"], np.min(df[\"value\"])*1.5))\n",
    "        img = df.pivot_table(columns=\"epoch\", index=\"config.budget\", values=\"value\")\n",
    "        img.index = img.index.astype(\"str\") #plotly interprets the y axis as numeric otherwise\n",
    "        return px.imshow(img)\n",
    "    elif viz == \"scatter\":\n",
    "        df = df.sort_values([\"epoch\", \"config.budget\"], ascending=[True, False])\n",
    "        df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "        df[\"epoch\"] = df[\"epoch\"].astype(\"str\")\n",
    "        return px.scatter(df, x=\"epoch\", y=\"config.budget\", size=\"count\", color=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def heatmap_app(groups=\"('fixed_01')\", dataset=\"529_pollen\", topology=\"wide_first\", loss=\"history_val_loss\", depth=\"8\", agg=\"avg\", residual_mode=\"none\", viz=\"imshow\", color_range=1.25):\n",
    "    query_string = f'''\n",
    "select \"config.budget\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}' and\n",
    "    \"config.depth\" = '{depth}'::int\n",
    "GROUP BY epoch, \"config.budget\"\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    \n",
    "    if viz == \"imshow\":\n",
    "        #df = df.query(\"count > 389\")\n",
    "        df[\"value\"] = -np.log(np.minimum(df[\"value\"], np.min(df[\"value\"])*color_range))\n",
    "        img = df.pivot_table(columns=\"epoch\", index=\"config.budget\", values=\"value\")\n",
    "        img.index = img.index.astype(\"str\") #plotly interprets the y axis as numeric otherwise\n",
    "        return px.imshow(img)\n",
    "    elif viz == \"scatter\":\n",
    "        df = df.sort_values([\"epoch\", \"config.budget\"], ascending=[True, False])\n",
    "        df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "        df[\"epoch\"] = df[\"epoch\"].astype(\"str\")\n",
    "        return px.scatter(df, x=\"epoch\", y=\"config.budget\", size=\"count\", color=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Your Axis Heatmap Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "axis = [\"dataset\", \"topology\", \"residual_mode\", \"budget\"]\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"], y_dim=axis)\n",
    "def heatmap_app(groups=\"('fixed_01')\", x_dim=\"epoch\", y_dim=\"budget\", budget=\"64\", dataset=\"537_houses\", topology=\"wide_first\", loss=\"history_val_mean_squared_error\", agg=\"avg\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    axis = [\"dataset\", \"topology\", \"residual_mode\", \"budget\"]\n",
    "    args = locals()\n",
    "    filter_string = \" and \".join([f'''\"config.{s}\"='{args[s]}' ''' for s in axis if s != y_dim])\n",
    "    query_string = f'''\n",
    "select \"config.{y_dim}\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    {filter_string}\n",
    "GROUP BY {x_dim}, \"config.{y_dim}\"\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    \n",
    "    if viz == \"imshow\":\n",
    "        #df = df.query(\"count > 389\")\n",
    "        img = df.pivot_table(columns=x_dim, index=\"config.\"+y_dim, values=\"value\")\n",
    "        img.index = img.index.astype(\"str\") #plotly interprets the y axis as numeric otherwise\n",
    "        return px.imshow(img)\n",
    "    elif viz == \"scatter\":\n",
    "        df = df.sort_values([\"epoch\", \"config.budget\"], ascending=[True, False])\n",
    "        df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "        df[\"epoch\"] = df[\"epoch\"].astype(\"str\")\n",
    "        return px.scatter(df, x=\"epoch\", y=\"config.budget\", size=\"count\", color=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Plot for Single budget x dataset x topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### single run app\n",
    "\n",
    "@interact(**options)\n",
    "def heatmap_app(dataset=\"537_houses\", topology=\"wide_first\", loss=\"history_val_mean_squared_error\", agg=\"avg\", residual_mode=\"none\",\n",
    "               budget=\"256\"):\n",
    "    query_string = f'''\n",
    "select a.val as value, a.epoch, run_name\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN ('exp00', 'exp01') and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}' and\n",
    "    \"config.budget\"='{budget}'\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    return px.line(df, x=\"epoch\", y=\"value\", color=\"run_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "- 537 houses, (val) kl divergence, trapezoid\n",
    "- sleep, trapezoid, history_val_loss, 16777216\n",
    "\n",
    "Notes:\n",
    "- Logarithmic color map\n",
    "- look into why sleep runs crash for high budgets\n",
    "- plateau effect\n",
    "- review stopping configurations / what is reasonable number of iterations?\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "## Look at \"plateau\" feature from Charle's notebooks\n",
    "## Add dataset, dataset complexity, as axis\n",
    "## Add topology as an axis\n",
    "### learning rate / optimizers / other axis to add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To re-run using fixed epoch length, how long is reasonable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def heatmap_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    avg(array_length(t.history_loss, 1)) as avg,\n",
    "    min(array_length(t.history_loss, 1)) as min,\n",
    "    max(array_length(t.history_loss, 1)) as max,\n",
    "    stddev(array_length(t.history_loss, 1)) as std\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "GROUP BY \"config.budget\"\n",
    "'''\n",
    "    df = cached_query(query_string).sort_values(\"config.budget\")\n",
    "    \n",
    "    return px.line(df, x=\"config.budget\", y=\"avg\", error_y=\"std\", log_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Epoch Count App\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def epoch_count_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    array_length(t.history_loss, 1) as num_epochs\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    df = df.sort_values(\"config.budget\")\n",
    "    df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "    \n",
    "    return px.scatter(df, x=\"config.budget\", y=\"num_epochs\", title=f\"Number of epochs for {dataset}, {topology} in {groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Epoch Count App\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def epoch_count_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    \"config.topology\",\n",
    "    array_length(t.history_loss, 1) as num_epochs\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "'''\n",
    "    df = cached_query(query_string).sort_values(\"config.budget\")\n",
    "    \n",
    "    df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "    \n",
    "    return px.violin(df,\n",
    "                    x=\"config.budget\",\n",
    "                    y=\"num_epochs\",\n",
    "                    color=\"config.topology\",\n",
    "                     box=True,\n",
    "                    title=f\"Number of epochs for {dataset}, in {groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Epoch Count App\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def epoch_count_agg_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    \"config.dataset\",\n",
    "    array_length(t.history_loss, 1) as num_epochs\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "'''\n",
    "    df = cached_query(query_string).sort_values(\"config.budget\")\n",
    "    \n",
    "    df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "    \n",
    "    return px.violin(df,\n",
    "                    x=\"config.budget\",\n",
    "                    y=\"num_epochs\",\n",
    "                    color=\"config.dataset\",\n",
    "                     box=True,\n",
    "                    title=f\"Number of epochs for {topology}, in {groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate 90th percentile epoch length for each experiment\n",
    "query_string = f'''\n",
    "select\n",
    "    (percentile_disc(0.9) within group (order by array_length(t.history_loss, 1))) as epoch_90_pctile,\n",
    "    \"config.topology\",\n",
    "    \"config.residual_mode\",\n",
    "    \"config.dataset\",\n",
    "    \"config.budget\"\n",
    "FROM\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN ('exp00','exp01')\n",
    "GROUP BY\n",
    "    \"config.topology\",\n",
    "    \"config.residual_mode\",\n",
    "    \"config.dataset\",\n",
    "    \"config.budget\"\n",
    "'''\n",
    "\n",
    "df = cached_query(query_string)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate 90th percentile epoch length for each experiment\n",
    "query_string = f'''\n",
    "    select\n",
    "        max(array_length(t.history_loss, 1)) as epoch_max,\n",
    "        (percentile_disc(0.90) within group (order by array_length(t.history_loss, 1))) as epoch_90_pctile,\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\"\n",
    "    FROM\n",
    "        materialized_experiments_0 t\n",
    "    WHERE\n",
    "        \"groupname\" IN ('exp00','exp01')\n",
    "    GROUP BY\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\"\n",
    "'''\n",
    "\n",
    "df = cached_query(query_string)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby([\"config.topology\", \"config.residual_mode\", \"config.dataset\"]).max().drop(\"config.budget\", axis=1)\n",
    "\n",
    "df2.to_csv(\"epoch_90th_pctile.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"epoch_90th_pctile_each_budget.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, we want to add dataset (or some statistic derived from the dataset's complexity) and topology as axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cached_query('''select * from materialized_experiments_0 WHERE \"groupname\" IN ('exp04') limit 10''')\n",
    "display(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the heatmap of validation loss for one topology, one dataset, over iteration count and different budgets\n",
    "\n",
    "q = '''\n",
    "select \"config.budget\", avg(a.val) as val_loss, avg(a.loss) as train_loss, count(a.loss), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.history_val_mean_squared_error, t.history_mean_squared_error) WITH ORDINALITY as a(val, loss, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN ('exp00', 'exp01') and\n",
    "    \"config.dataset\"='537_houses' and\n",
    "    \"config.topology\"='wide_first' and\n",
    "    \"config.residual_mode\"='none'\n",
    "GROUP BY epoch, \"config.budget\"\n",
    "'''\n",
    "\n",
    "# q = '''\n",
    "# select distinct(\"name\")\n",
    "# from\n",
    "#     materialized_experiments_0\n",
    "# WHERE\n",
    "#     \"groupname\" IN ('exp00', 'exp01') and\n",
    "#     \"config.dataset\"='537_houses' and\n",
    "#     \"config.topology\"='wide_first' and\n",
    "#     \"config.residual_mode\"='none' and\n",
    "#     \"config.budget\"=262144\n",
    "# limit 10\n",
    "# '''\n",
    "\n",
    "df = cache_query(q)\n",
    "display(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate max of 95th percentile epoch length and iterations to smallest loss over all topologies for each budget and dataset\n",
    "query_string = f'''\n",
    "select max(max_iterations) as max_iterations,\n",
    "       max(p95) as p95,\n",
    "       max(p90) as p90,\n",
    "       max(p67) as p67,\n",
    "       max(p50) as p50,\n",
    "       max(p33) as p33,\n",
    "       max(avg_iterations) as avg_iterations,\n",
    "       max(foo.max_patience) as max_patience,\n",
    "       min(foo.min_patience) as min_patience,\n",
    "    foo.\"config.dataset\",\n",
    "    foo.\"config.budget\"\n",
    "--    foo.\"config.topology\",\n",
    "--    foo.\"config.residual_mode\"\n",
    "FROM\n",
    "    (SELECT\n",
    "        MAX(iterations) as max_iterations,\n",
    "        (percentile_disc(0.95) within group (order by iterations ASC)) as p95,\n",
    "        (percentile_disc(0.9) within group (order by iterations ASC)) as p90,\n",
    "        (percentile_disc(0.67) within group (order by iterations ASC)) as p67,\n",
    "        (percentile_disc(0.5) within group (order by iterations ASC)) as p50,\n",
    "        (percentile_disc(0.33) within group (order by iterations ASC)) as p33,\n",
    "        AVG(iterations) as avg_iterations,\n",
    "        max(\"config.early_stopping.patience\") as max_patience,\n",
    "        min(\"config.early_stopping.patience\") as min_patience,\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\",\n",
    "        \"config.depth\"\n",
    "    FROM\n",
    "        materialized_experiments_0 t\n",
    "    WHERE\n",
    "        \"groupname\" IN ('exp00','exp01')\n",
    "    GROUP BY\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\",\n",
    "        \"config.depth\") AS foo\n",
    "    GROUP BY\n",
    "        foo.\"config.dataset\",\n",
    "        foo.\"config.budget\"\n",
    "--        foo.\"config.topology\",\n",
    "--        foo.\"config.residual_mode\"\n",
    "'''\n",
    "\n",
    "df = cached_query(query_string)\n",
    "display(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df['config.dataset']))\n",
    "# print(pd.unique(df['config.topology']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'connect_4'\n",
    "filtered = df[df['config.dataset'] == dataset]\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(filtered['config.budget'], filtered['max_iterations'], 'ok-', label='max_iterations')\n",
    "ax.plot(filtered['config.budget'], filtered['p95'], 'or-', label='p95')\n",
    "ax.plot(filtered['config.budget'], filtered['p90'], 'ob', label='p90')\n",
    "ax.plot(filtered['config.budget'], filtered['p67'], 'ob', label='p67')\n",
    "ax.plot(filtered['config.budget'], filtered['p50'], 'og-', label='p50')\n",
    "ax.plot(filtered['config.budget'], filtered['p33'], 'ob', label='p33')\n",
    "ax.plot(filtered['config.budget'], filtered['avg_iterations'], 'o-k', label='avg_percentile')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.legend()\n",
    "ax.set_xlabel('budget')\n",
    "ax.set_ylabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasets = [d for d in pd.unique(df['config.dataset']) if d not in {'nursery', 'adult'}]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for dataset in datasets:\n",
    "#     if dataset != '529_pollen':\n",
    "#         continue\n",
    "#     filtered = df[(df['config.dataset'] == dataset) & (df['config.topology'] == 'trapezoid') & (df['config.residual_mode'] == 'none')]\n",
    "    filtered = df[(df['config.dataset'] == dataset)]\n",
    "    budget = filtered['config.budget']\n",
    "    v = filtered['p95']\n",
    "#     v = np.log10(v)\n",
    "#     v_min = v.min()\n",
    "#     v_max = v.max()\n",
    "#     v_avg = v.mean()\n",
    "#     v_std = v.std()\n",
    "#     v_norm = (v - v_avg) / (v_std)\n",
    "#     ax.plot(budget, v, 'o-', label=dataset)\n",
    "    ax.plot(budget, v, 'o-', label=dataset)\n",
    "    print(filtered[filtered['config.budget'] == 8192]['p95'].iloc[0])\n",
    "    \n",
    "#     ax.plot(budget, budget * filtered[], 'o-', label=dataset)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('budget')\n",
    "    ax.set_ylabel('epochs / budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "for dataset in datasets:\n",
    "    filtered = df[(df['config.dataset'] == dataset)]\n",
    "    budget = filtered['config.budget']\n",
    "    v = filtered['p95']\n",
    "    x = np.log(budget)\n",
    "    y = np.log(v/budget)\n",
    "    X = np.reshape(x.to_numpy(), (len(x), 1))\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    print(f'{dataset} score: {reg.score(X, y)} coef: {reg.coef_} intercept: {reg.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def fit_above(x, y) :\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    x0, y0 = x[0] - 1, y[0]\n",
    "    x -= x0\n",
    "    y -= y0\n",
    "\n",
    "    def error_function_2(b, x, y) :\n",
    "        a = np.max((y - b) / x)\n",
    "        return np.sum((y - a * x - b)**2)\n",
    "\n",
    "    b = scipy.optimize.minimize(error_function_2, [0], args=(x, y)).x[0]\n",
    "\n",
    "    a = np.max((y - b) / x)\n",
    "\n",
    "    return a, b - a * x0 + y0\n",
    "\n",
    "datasets = [d for d in pd.unique(df['config.dataset']) if d not in {'nursery', 'adult'}]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for dataset in datasets:\n",
    "#     if dataset != '529_pollen':\n",
    "#         continue\n",
    "#     filtered = df[(df['config.dataset'] == dataset) & (df['config.topology'] == 'trapezoid') & (df['config.residual_mode'] == 'none')]\n",
    "    filtered = df[(df['config.dataset'] == dataset)]\n",
    "    budget = filtered['config.budget'].to_numpy()\n",
    "    v = filtered['avg_iterations'].to_numpy()\n",
    "    x = np.log(budget)\n",
    "#     x = 1.0 / budget\n",
    "#     y = np.log(v)\n",
    "#     y = np.log(v)\n",
    "    y = np.log(v)\n",
    "#     v = np.log10(v)\n",
    "#     v_min = v.min()\n",
    "#     v_max = v.max()\n",
    "#     v_avg = v.mean()\n",
    "#     v_std = v.std()\n",
    "#     v_norm = (v - v_avg) / (v_std)\n",
    "#     ax.plot(budget, v, 'o-', label=dataset)\n",
    "    p = ax.plot(x, y, 'o-', label=dataset)\n",
    "    \n",
    "#     X = np.reshape(x, (len(x), 1))\n",
    "#     reg = LinearRegression().fit(X, y)\n",
    "#     print(f'{dataset} score: {reg.score(X, y)} coef: {reg.coef_} intercept: {reg.intercept_}')\n",
    "    \n",
    "#     ax.plot(x, y, 'o-', label=dataset)\n",
    "#     ax.plot(x, reg.coef_ * x + reg.intercept_, '-', color = p[0].get_color())\n",
    "    \n",
    "    m, b = fit_above(x,y)\n",
    "    extra = .5\n",
    "    b+=extra\n",
    "    plt.plot(x, m*x + b, '-', color=p[0].get_color())\n",
    "    print(f'{dataset} m: {m} b: {b}')\n",
    "#     ax.plot(budget, budget * filtered[], 'o-', label=dataset)\n",
    "\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('log(budget)')\n",
    "    ax.set_ylabel('log(95th percentile epochs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def fit_above(x, y) :\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    x0, y0 = x[0] - 1, y[0]\n",
    "    x -= x0\n",
    "    y -= y0\n",
    "\n",
    "    def error_function_2(b, x, y) :\n",
    "        a = np.max((y - b) / x)\n",
    "        return np.sum((y - a * x - b)**2)\n",
    "\n",
    "    b = scipy.optimize.minimize(error_function_2, [0], args=(x, y)).x[0]\n",
    "\n",
    "    a = np.max((y - b) / x)\n",
    "\n",
    "    return a, b - a * x0 + y0\n",
    "\n",
    "datasets = [d for d in pd.unique(df['config.dataset']) if d not in {'nursery', 'adult'}]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for dataset in datasets:\n",
    "#     if dataset != '529_pollen':\n",
    "#         continue\n",
    "#     filtered = df[(df['config.dataset'] == dataset) & (df['config.topology'] == 'trapezoid') & (df['config.residual_mode'] == 'none')]\n",
    "    filtered = df[(df['config.dataset'] == dataset)]\n",
    "    budget = filtered['config.budget'].to_numpy()\n",
    "    v = filtered['avg_iterations'].to_numpy()\n",
    "    x = np.log(budget)\n",
    "#     x = 1.0 / budget\n",
    "#     y = np.log(v)\n",
    "#     y = np.log(v)\n",
    "    y = np.log(v)\n",
    "#     v = np.log10(v)\n",
    "#     v_min = v.min()\n",
    "#     v_max = v.max()\n",
    "#     v_avg = v.mean()\n",
    "#     v_std = v.std()\n",
    "#     v_norm = (v - v_avg) / (v_std)\n",
    "#     ax.plot(budget, v, 'o-', label=dataset)\n",
    "#     p = ax.plot(x, y, 'o-', label=dataset)\n",
    "    \n",
    "#     X = np.reshape(x, (len(x), 1))\n",
    "#     reg = LinearRegression().fit(X, y)\n",
    "#     print(f'{dataset} score: {reg.score(X, y)} coef: {reg.coef_} intercept: {reg.intercept_}')\n",
    "    \n",
    "#     ax.plot(x, y, 'o-', label=dataset)\n",
    "#     ax.plot(x, reg.coef_ * x + reg.intercept_, '-', color = p[0].get_color())\n",
    "    \n",
    "    m, b = fit_above(x,y)\n",
    "    extra = .1\n",
    "    b+=extra\n",
    "#     plt.plot(x, m*x + b, '-', color=p[0].get_color())\n",
    "    print(f'{dataset} m: {m} b: {b}')\n",
    "#     ax.plot(budget, budget * filtered[], 'o-', label=dataset)\n",
    "    bound = np.ceil(np.exp(m * np.log(budget) + b))\n",
    "    p = ax.plot(x, bound/v , 'o-', label=dataset)\n",
    "    print(f'dataset {dataset} {bound}')\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('budget')\n",
    "    ax.set_ylabel('epochs / budget')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [d for d in pd.unique(df['config.dataset']) if d not in {'nursery', 'adult'}]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for dataset in datasets:\n",
    "#     if dataset != '529_pollen':\n",
    "#         continue\n",
    "#     filtered = df[(df['config.dataset'] == dataset) & (df['config.topology'] == 'trapezoid') & (df['config.residual_mode'] == 'none')]\n",
    "    filtered = df[(df['config.dataset'] == dataset)]\n",
    "    budget = filtered['config.budget']\n",
    "    v = filtered['p95']\n",
    "#     v = np.log10(v)\n",
    "#     v_min = v.min()\n",
    "#     v_max = v.max()\n",
    "#     v_avg = v.mean()\n",
    "#     v_std = v.std()\n",
    "#     v_norm = (v - v_avg) / (v_std)\n",
    "#     ax.plot(budget, v, 'o-', label=dataset)\n",
    "    ax.plot(budget, v, 'o-', label=dataset)\n",
    "    print(filtered[filtered['config.budget'] == 8192]['p95'].iloc[0])\n",
    "    \n",
    "#     ax.plot(budget, budget * filtered[], 'o-', label=dataset)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('budget')\n",
    "#     ax.set_ylabel('epochs / budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = f'''\n",
    "    SELECT\n",
    "        MAX(iterations) as max_iterations,\n",
    "        (percentile_disc(0.95) within group (order by iterations ASC)) as p95,\n",
    "        (percentile_disc(0.9) within group (order by iterations ASC)) as p90,\n",
    "        (percentile_disc(0.67) within group (order by iterations ASC)) as p67,\n",
    "        (percentile_disc(0.5) within group (order by iterations ASC)) as p50,\n",
    "        (percentile_disc(0.33) within group (order by iterations ASC)) as p33,\n",
    "        AVG(iterations) as avg_percentile,\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\",\n",
    "        max(\"config.early_stopping.patience\") as max_patience,\n",
    "        min(\"config.early_stopping.patience\") as min_patience,\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\"\n",
    "    FROM\n",
    "        materialized_experiments_0 t\n",
    "    WHERE\n",
    "        \"groupname\" IN ('exp00','exp01','exp02','exp05','exp06')\n",
    "    GROUP BY\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\"\n",
    "'''\n",
    "\n",
    "df = cached_query(query_string)\n",
    "display(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [d for d in pd.unique(df['config.dataset']) if d not in {'nursery', 'adult'}]\n",
    "\n",
    "styles = ['']\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for dataset in datasets:\n",
    "    f1 = df[df['config.dataset'] == dataset]\n",
    "    for topology in pd.unique(f1['config.topology']):\n",
    "        filtered = f1[f1['config.topology'] == topology]\n",
    "        v = filtered['p95']\n",
    "        v = np.log(v)\n",
    "        v_min = v.min()\n",
    "        v_max = v.max()\n",
    "        v_avg = v.mean()\n",
    "        v_std = v.std()\n",
    "        v_norm = (v - v_avg) / (v_std)\n",
    "        ax.plot(filtered['config.budget'], v_norm, 'o', label=f'{dataset} {topology}')\n",
    "\n",
    "    #     ax.set_yscale('log')\n",
    "        ax.set_xscale('log')\n",
    "#         ax.legend()\n",
    "        ax.set_xlabel('budget')\n",
    "        ax.set_ylabel('normed epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
