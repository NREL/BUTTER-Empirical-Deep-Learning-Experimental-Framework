{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "toxic-pepper",
   "metadata": {},
   "source": [
    "# Visualizations in Plotly for the DMP Aspect Test Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from dmp.data.logging import _get_sql_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from joblib import Memory\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = _get_sql_engine()\n",
    "\n",
    "memory = Memory(location=\"./cache\", verbose=0)\n",
    "\n",
    "def query(query_string):\n",
    "    with db.connect() as engine:\n",
    "        return pd.read_sql(query_string, engine)\n",
    "\n",
    "cached_query = memory.cache(query)\n",
    "\n",
    "def clear_cache():\n",
    "    memory.clear()\n",
    "    \n",
    "options = {\n",
    "    \"dataset\": ['529_pollen',\n",
    "        'sleep',\n",
    "        'adult',\n",
    "        '537_houses',\n",
    "        'nursery',\n",
    "        '201_pol',\n",
    "        'mnist',\n",
    "        'connect_4',\n",
    "        'wine_quality_white'],\n",
    "    \"agg\": [\"avg\", \"min\", \"max\"],\n",
    "    \"topology\" : [\"exponential\", \"rectangle\", \"trapezoid\", \"wide_first\"],\n",
    "    \"loss\": ['history_loss', 'history_hinge', 'history_accuracy',\n",
    "       'history_val_loss', 'history_val_hinge', 'history_val_accuracy',\n",
    "       'history_squared_hinge', 'history_cosine_similarity',\n",
    "       'history_val_squared_hinge', 'history_mean_squared_error',\n",
    "       'history_mean_absolute_error', 'history_val_cosine_similarity',\n",
    "       'history_val_mean_squared_error', 'history_root_mean_squared_error',\n",
    "       'history_val_mean_absolute_error',\n",
    "       'history_kullback_leibler_divergence',\n",
    "       'history_val_root_mean_squared_error',\n",
    "       'history_mean_squared_logarithmic_error',\n",
    "       'history_val_kullback_leibler_divergence',\n",
    "       'history_val_mean_squared_logarithmic_error'],\n",
    "    \"residual_mode\": [\"none\", \"full\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-liability",
   "metadata": {},
   "source": [
    "# 3D Heatmap App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-valve",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def heatmap_app_3d(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", loss=\"history_val_mean_squared_error\", agg=\"avg\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "    select \"config.budget\", \"config.depth\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "    from\n",
    "        materialized_experiments_0 t,\n",
    "        unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "    WHERE\n",
    "        \"groupname\" IN {groups} and\n",
    "        \"config.dataset\"='{dataset}' and\n",
    "        \"config.topology\"='{topology}' and\n",
    "        \"config.residual_mode\"='{residual_mode}'\n",
    "    GROUP BY epoch, \"config.budget\", \"config.depth\"\n",
    "    '''\n",
    "    df = cached_query(query_string)#.query(\"count == 30\")\n",
    "    \n",
    "    if viz==\"scatter\":\n",
    "        \n",
    "        fig = px.scatter_3d(df,\n",
    "                    x='config.depth',\n",
    "                    y='config.budget',\n",
    "                    z='epoch',\n",
    "                    color='value',\n",
    "                    log_y=True,\n",
    "                    opacity=0.25)\n",
    "        fig.show()\n",
    "        \n",
    "    elif viz==\"imshow\":\n",
    "\n",
    "        dimensions = [\"config.budget\", \"config.depth\", \"epoch\"]\n",
    "\n",
    "        df[dimensions[0]] = df[dimensions[0]].astype(int)\n",
    "        df[dimensions[1]] = df[dimensions[1]].astype(int)\n",
    "        df[dimensions[2]] = df[dimensions[2]].astype(int)\n",
    "\n",
    "        x_labels, y_labels, z_labels = [sorted(df[dim].unique()) for dim in dimensions]\n",
    "        X, Y, Z = np.mgrid[0:len(x_labels), 0:len(y_labels), 0:len(z_labels)]\n",
    "        values = np.empty((X+Y+Z).shape)\n",
    "        values[:] = np.NaN\n",
    "\n",
    "        x_idx = {a:b for b,a in enumerate(x_labels)}\n",
    "        y_idx = {a:b for b,a in enumerate(y_labels)}\n",
    "        z_idx = {a:b for b,a in enumerate(z_labels)}\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            values[x_idx[row[dimensions[0]]], y_idx[row[dimensions[1]]], z_idx[row[dimensions[2]]]] = row[\"value\"]\n",
    "\n",
    "\n",
    "        fig = go.Figure(data=go.Volume(\n",
    "            x=X.flatten(),\n",
    "            y=Y.flatten(),\n",
    "            z=Z.flatten(),\n",
    "            value=values.flatten(),\n",
    "            opacity=0.1, # needs to be small to see through all surfaces\n",
    "            surface_count=30\n",
    "            ))\n",
    "\n",
    "        fig.update_layout(scene = dict(\n",
    "                            xaxis = dict(ticktext=x_labels,\n",
    "                                         tickvals=list(range(0,len(x_labels))),\n",
    "                                         title=dimensions[0]),\n",
    "\n",
    "                            yaxis = dict(ticktext=y_labels,\n",
    "                                         tickvals=list(range(0,len(y_labels))),\n",
    "                                         title=dimensions[1]),\n",
    "\n",
    "                            zaxis = dict(ticktext=z_labels,\n",
    "                                         tickvals=list(range(0,len(z_labels))),\n",
    "                                         title=dimensions[2]),\n",
    "\n",
    "\n",
    "                            ),\n",
    "                          width=700, height=700,\n",
    "                         title=f\"{loss} for {dataset}, {topology}, residual {residual_mode}\")\n",
    "        fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-recognition",
   "metadata": {},
   "source": [
    "# 2D Heatmap App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-illustration",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def heatmap_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", loss=\"history_val_mean_squared_error\", agg=\"avg\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select \"config.budget\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "GROUP BY epoch, \"config.budget\"\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    \n",
    "    if viz == \"imshow\":\n",
    "        #df = df.query(\"count > 389\")\n",
    "        df[\"value\"] = np.log(df[\"value\"])\n",
    "        img = df.pivot_table(columns=\"epoch\", index=\"config.budget\", values=\"value\")\n",
    "        img.index = img.index.astype(\"str\") #plotly interprets the y axis as numeric otherwise\n",
    "        return px.imshow(img)\n",
    "    elif viz == \"scatter\":\n",
    "        df = df.sort_values([\"epoch\", \"config.budget\"], ascending=[True, False])\n",
    "        df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "        df[\"epoch\"] = df[\"epoch\"].astype(\"str\")\n",
    "        return px.scatter(df, x=\"epoch\", y=\"config.budget\", size=\"count\", color=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-carolina",
   "metadata": {},
   "source": [
    "## Choose Your Axis Heatmap Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "axis = [\"dataset\", \"topology\", \"residual_mode\", \"budget\"]\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"], y_dim=axis)\n",
    "def heatmap_app(groups=\"('exp00', 'exp01')\", x_dim=\"epoch\", y_dim=\"budget\", budget=\"64\", dataset=\"537_houses\", topology=\"wide_first\", loss=\"history_val_mean_squared_error\", agg=\"avg\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    axis = [\"dataset\", \"topology\", \"residual_mode\", \"budget\"]\n",
    "    args = locals()\n",
    "    filter_string = \" and \".join([f'''\"config.{s}\"='{args[s]}' ''' for s in axis if s != y_dim])\n",
    "    query_string = f'''\n",
    "select \"config.{y_dim}\", {agg}(a.val) as value, count(a.val), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    {filter_string}\n",
    "GROUP BY {x_dim}, \"config.{y_dim}\"\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    \n",
    "    if viz == \"imshow\":\n",
    "        #df = df.query(\"count > 389\")\n",
    "        img = df.pivot_table(columns=x_dim, index=\"config.\"+y_dim, values=\"value\")\n",
    "        img.index = img.index.astype(\"str\") #plotly interprets the y axis as numeric otherwise\n",
    "        return px.imshow(img)\n",
    "    elif viz == \"scatter\":\n",
    "        df = df.sort_values([\"epoch\", \"config.budget\"], ascending=[True, False])\n",
    "        df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "        df[\"epoch\"] = df[\"epoch\"].astype(\"str\")\n",
    "        return px.scatter(df, x=\"epoch\", y=\"config.budget\", size=\"count\", color=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-simon",
   "metadata": {},
   "source": [
    "# Line Plot for Single budget x dataset x topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "### single run app\n",
    "\n",
    "@interact(**options)\n",
    "def heatmap_app(dataset=\"537_houses\", topology=\"wide_first\", loss=\"history_val_mean_squared_error\", agg=\"avg\", residual_mode=\"none\",\n",
    "               budget=\"256\"):\n",
    "    query_string = f'''\n",
    "select a.val as value, a.epoch, run_name\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN ('exp00', 'exp01') and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}' and\n",
    "    \"config.budget\"='{budget}'\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    return px.line(df, x=\"epoch\", y=\"value\", color=\"run_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-blame",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "- 537 houses, (val) kl divergence, trapezoid\n",
    "- sleep, trapezoid, history_val_loss, 16777216\n",
    "\n",
    "Notes:\n",
    "- Logarithmic color map\n",
    "- look into why sleep runs crash for high budgets\n",
    "- plateau effect\n",
    "- review stopping configurations / what is reasonable number of iterations?\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "## Look at \"plateau\" feature from Charle's notebooks\n",
    "## Add dataset, dataset complexity, as axis\n",
    "## Add topology as an axis\n",
    "### learning rate / optimizers / other axis to add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-sharing",
   "metadata": {},
   "source": [
    "# To re-run using fixed epoch length, how long is reasonable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual\n",
    "def heatmap_app(groups=\"('exp00', 'exp01')\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    \"config.dataset\",\n",
    "    avg(array_length(t.history_loss, 1)) as avg,\n",
    "    min(array_length(t.history_loss, 1)) as min,\n",
    "    max(array_length(t.history_loss, 1)) as max,\n",
    "    (percentile_disc(0.90) within group (order by array_length(t.history_loss, 1))) as pctile_90,\n",
    "    stddev(array_length(t.history_loss, 1)) as std\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups}\n",
    "GROUP BY \"config.budget\", \"config.dataset\"\n",
    "'''\n",
    "    df = cached_query(query_string).sort_values(\"config.budget\")\n",
    "    \n",
    "    df[\"spread\"] = (df[\"max\"] - df[\"min\"])/2\n",
    "    \n",
    "    fig = px.line(df, x=\"config.budget\", y=\"val\", color=\"config.dataset\", log_x=True, log_y=True)\n",
    "    \n",
    "    budgets = np.array(sorted(df[\"config.budget\"].unique()))\n",
    "    #fig.add_trace(go.Line(y=1/budgets, x=budgets, name=\"1/budget\", line=dict(color='red', width=4, dash='dash') ))  \n",
    "    #fig.add_trace(go.Line(y=5000/budgets, x=budgets, name=\"5000 * 1/budget\", line=dict(color='black', width=4, dash='dash') ))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Heapmap App using Imshow\n",
    "\n",
    "@interact_manual\n",
    "def heatmap_app(groups=\"('exp00', 'exp01')\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    \"config.dataset\",\n",
    "    avg(array_length(t.history_loss, 1)) as avg,\n",
    "    min(array_length(t.history_loss, 1)) as min,\n",
    "    max(array_length(t.history_loss, 1)) as max,\n",
    "    (percentile_disc(0.90) within group (order by array_length(t.history_loss, 1))) as pctile_90,\n",
    "    stddev(array_length(t.history_loss, 1)) as std\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups}\n",
    "GROUP BY \"config.budget\", \"config.dataset\"\n",
    "'''\n",
    "    df = cached_query(query_string).sort_values(\"config.budget\")\n",
    "    \n",
    "    df[\"pctile_90*budget\"] = df[\"pctile_90\"]*df[\"config.budget\"]\n",
    "    \n",
    "    fig = px.line(df, x=\"pctile_90*budget\", y=\"pctile_90\", color=\"config.dataset\", log_x=True, log_y=True)\n",
    "    \n",
    "    budgets = np.array(sorted(df[\"config.budget\"].unique()))\n",
    "    #fig.add_trace(go.Line(y=1/budgets, x=budgets, name=\"1/budget\", line=dict(color='red', width=4, dash='dash') ))  \n",
    "    #fig.add_trace(go.Line(y=5000/budgets, x=budgets, name=\"5000 * 1/budget\", line=dict(color='black', width=4, dash='dash') ))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-attack",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Epoch Count App\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def epoch_count_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    array_length(t.history_loss, 1) as num_epochs\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    df = df.sort_values(\"config.budget\")\n",
    "    df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "    \n",
    "    return px.scatter(df, x=\"config.budget\", y=\"num_epochs\", title=f\"Number of epochs for {dataset}, {topology} in {groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Epoch Count App\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def epoch_count_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    \"config.topology\",\n",
    "    array_length(t.history_loss, 1) as num_epochs\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "'''\n",
    "    df = cached_query(query_string).sort_values(\"config.budget\")\n",
    "    \n",
    "    df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "    \n",
    "    return px.violin(df,\n",
    "                    x=\"config.budget\",\n",
    "                    y=\"num_epochs\",\n",
    "                    color=\"config.topology\",\n",
    "                     box=True,\n",
    "                    title=f\"Number of epochs for {dataset}, in {groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Epoch Count App\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def epoch_count_agg_app(groups=\"('exp00', 'exp01')\", dataset=\"537_houses\", topology=\"wide_first\", residual_mode=\"none\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select\n",
    "    \"config.budget\",\n",
    "    \"config.dataset\",\n",
    "    array_length(t.history_loss, 1) as num_epochs\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.residual_mode\"='{residual_mode}'\n",
    "'''\n",
    "    df = cached_query(query_string).sort_values(\"config.budget\")\n",
    "    \n",
    "    df[\"config.budget\"] = df[\"config.budget\"].astype(\"str\")\n",
    "    \n",
    "    return px.violin(df,\n",
    "                    x=\"config.budget\",\n",
    "                    y=\"num_epochs\",\n",
    "                    color=\"config.dataset\",\n",
    "                     box=True,\n",
    "                    title=f\"Number of epochs for {topology}, in {groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate 90th percentile epoch length for each experiment\n",
    "query_string = f'''\n",
    "select\n",
    "    (percentile_disc(0.9) within group (order by array_length(t.history_loss, 1))) as epoch_90_pctile,\n",
    "    \"config.topology\",\n",
    "    \"config.residual_mode\",\n",
    "    \"config.dataset\",\n",
    "    \"config.budget\"\n",
    "FROM\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN ('exp00','exp01')\n",
    "GROUP BY\n",
    "    \"config.topology\",\n",
    "    \"config.residual_mode\",\n",
    "    \"config.dataset\",\n",
    "    \"config.budget\"\n",
    "'''\n",
    "\n",
    "df = cached_query(query_string)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate 90th percentile epoch length for each experiment\n",
    "query_string = f'''\n",
    "    select\n",
    "        max(array_length(t.history_loss, 1)) as epoch_max,\n",
    "        (percentile_disc(0.90) within group (order by array_length(t.history_loss, 1))) as epoch_90_pctile,\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\"\n",
    "    FROM\n",
    "        materialized_experiments_0 t\n",
    "    WHERE\n",
    "        \"groupname\" IN ('exp00','exp01')\n",
    "    GROUP BY\n",
    "        \"config.topology\",\n",
    "        \"config.residual_mode\",\n",
    "        \"config.dataset\",\n",
    "        \"config.budget\"\n",
    "'''\n",
    "\n",
    "df = cached_query(query_string)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby([\"config.topology\", \"config.residual_mode\", \"config.dataset\"]).max().drop(\"config.budget\", axis=1)\n",
    "\n",
    "df2.to_csv(\"epoch_90th_pctile.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"epoch_90th_pctile_each_budget.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, we want to add dataset (or some statistic derived from the dataset's complexity) and topology as axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-premium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cached_query('''select * from materialized_experiments_0 WHERE \"groupname\" IN ('exp04') limit 10''')\n",
    "display(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the heatmap of validation loss for one topology, one dataset, over iteration count and different budgets\n",
    "\n",
    "q = '''\n",
    "select \"config.budget\", avg(a.val) as val_loss, avg(a.loss) as train_loss, count(a.loss), a.epoch\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.history_val_mean_squared_error, t.history_mean_squared_error) WITH ORDINALITY as a(val, loss, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN ('exp00', 'exp01') and\n",
    "    \"config.dataset\"='537_houses' and\n",
    "    \"config.topology\"='wide_first' and\n",
    "    \"config.residual_mode\"='none'\n",
    "GROUP BY epoch, \"config.budget\"\n",
    "'''\n",
    "\n",
    "# q = '''\n",
    "# select distinct(\"name\")\n",
    "# from\n",
    "#     materialized_experiments_0\n",
    "# WHERE\n",
    "#     \"groupname\" IN ('exp00', 'exp01') and\n",
    "#     \"config.dataset\"='537_houses' and\n",
    "#     \"config.topology\"='wide_first' and\n",
    "#     \"config.residual_mode\"='none' and\n",
    "#     \"config.budget\"=262144\n",
    "# limit 10\n",
    "# '''\n",
    "\n",
    "df = cache_query(q)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the heatmap of validation loss for one topology, one dataset, over iteration count and different budgets\n",
    "\n",
    "query_string = f'''\n",
    "select\n",
    "    \"config.dataset\",\n",
    "    avg(ln(array_length(t.history_loss, 1))) as log_avg_epoch\n",
    "from\n",
    "    materialized_experiments_0 t\n",
    "WHERE\n",
    "    \"groupname\" IN ('exp00', 'exp01')\n",
    "GROUP BY \"config.dataset\"\n",
    "'''\n",
    "\n",
    "#(percentile_disc(0.90) within group (order by array_length(t.history_loss, 1))) as val\n",
    "\n",
    "# q = '''\n",
    "# select distinct(\"name\")\n",
    "# from\n",
    "#     materialized_experiments_0\n",
    "# WHERE\n",
    "#     \"groupname\" IN ('exp00', 'exp01') and\n",
    "#     \"config.dataset\"='537_houses' and\n",
    "#     \"config.topology\"='wide_first' and\n",
    "#     \"config.residual_mode\"='none' and\n",
    "#     \"config.budget\"=262144\n",
    "# limit 10\n",
    "# '''\n",
    "\n",
    "df = cached_query(query_string).sort_values(\"log_avg_epoch\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-dance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
