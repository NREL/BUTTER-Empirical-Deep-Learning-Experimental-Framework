{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from dmp.data.logging import _get_sql_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from joblib import Memory\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import scipy.interpolate\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = _get_sql_engine()\n",
    "\n",
    "memory = Memory(location=\"./cache\", verbose=0)\n",
    "\n",
    "def query(query_string):\n",
    "    with db.connect() as engine:\n",
    "        return pd.read_sql(query_string, engine)\n",
    "\n",
    "cached_query = memory.cache(query)\n",
    "\n",
    "def clear_cache():\n",
    "    memory.clear()\n",
    "    \n",
    "options = {\n",
    "    \"dataset\": ['529_pollen',\n",
    "        'sleep',\n",
    "        'adult',\n",
    "        '537_houses',\n",
    "        'nursery',\n",
    "        '201_pol',\n",
    "        'mnist',\n",
    "        'connect_4',\n",
    "        'wine_quality_white'],\n",
    "    \"agg\": [\"avg\", \"min\", \"max\"],\n",
    "    \"topology\" : [\"exponential\", \"rectangle\", \"trapezoid\", \"wide_first\"],\n",
    "    \"loss\": ['history_loss', 'history_hinge', 'history_accuracy',\n",
    "       'history_val_loss', 'history_val_hinge', 'history_val_accuracy',\n",
    "       'history_squared_hinge', 'history_cosine_similarity',\n",
    "       'history_val_squared_hinge', 'history_mean_squared_error',\n",
    "       'history_mean_absolute_error', 'history_val_cosine_similarity',\n",
    "       'history_val_mean_squared_error', 'history_root_mean_squared_error',\n",
    "       'history_val_mean_absolute_error',\n",
    "       'history_kullback_leibler_divergence',\n",
    "       'history_val_root_mean_squared_error',\n",
    "       'history_mean_squared_logarithmic_error',\n",
    "       'history_val_kullback_leibler_divergence',\n",
    "       'history_val_mean_squared_logarithmic_error'],\n",
    "    \"residual_mode\": [\"none\", \"full\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-intention",
   "metadata": {},
   "source": [
    "# Facet Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-thesis",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_string = f'''\n",
    "select \"config.budget\", avg(a.val) as value, count(a.val), a.epoch, \"config.dataset\", \"config.topology\", \"config.residual_mode\"\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.history_val_loss) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\"='fixed_01'\n",
    "GROUP BY epoch, \"config.budget\", \"config.dataset\", \"config.topology\", \"config.residual_mode\"\n",
    "'''\n",
    "df = cached_query(query_string)\n",
    "\n",
    "df[\"log_epoch\"] = np.log10((df[\"epoch\"]))\n",
    "\n",
    "df[\"config.residual_mode\"].replace({\"none\":\"\", \"full\":\"full residual\\n\"}, inplace=True)\n",
    "df[\"config.topology\"] = df[\"config.residual_mode\"] + df[\"config.topology\"]\n",
    "\n",
    "df[\"value\"] = np.log(df[\"value\"])\n",
    "\n",
    "x_axes = np.linspace(df[\"log_epoch\"].min(), df[\"log_epoch\"].max(), 500)\n",
    "\n",
    "ROWS = 7\n",
    "COLS = 6\n",
    "\n",
    "fig, axs = plt.subplots(ROWS,COLS, figsize=(11,8), dpi=300, sharex=True)\n",
    "\n",
    "i = 0\n",
    "for idx, gdf in df.groupby([\"config.dataset\", \"config.topology\"]):\n",
    "    img = np.ndarray(shape=(22,500))\n",
    "    \n",
    "    v_range = gdf[\"value\"].max() - gdf[\"value\"].min()\n",
    "\n",
    "    for row_idx, row_df in gdf.groupby(\"config.budget\"):\n",
    "        \n",
    "        color_scale = 0.2\n",
    "        \n",
    "        intp = scipy.interpolate.interp1d(row_df[\"log_epoch\"],\n",
    "                                          row_df[\"value\"],\n",
    "                                          kind='linear',\n",
    "                                          bounds_error=False)\n",
    "\n",
    "        row_idx = int(np.log2(row_idx)-5)\n",
    "        \n",
    "        vals = intp(x_axes)\n",
    "        vals = np.minimum(gdf[\"value\"].min()+(v_range*color_scale), vals)\n",
    "        img[row_idx, :] = vals\n",
    "\n",
    "        \n",
    "    #value_min = df[df[\"config.dataset\"]==idx[0]][\"value\"].min()\n",
    "    #value_max = df[df[\"config.dataset\"]==idx[0]][\"value\"].max()\n",
    "    \n",
    "    ax = axs[i//COLS, i%COLS]\n",
    "    pcm = ax.imshow(img, aspect=\"auto\", cmap=\"viridis_r\")#, vmin=value_min, vmax=value_max)\n",
    "    \n",
    "    X,Y = np.meshgrid(np.arange(0,500),np.arange(0, 22))\n",
    "    Z = np.power(10, x_axes[X])*np.power(2, Y+5)\n",
    "    \n",
    "    clevels = np.logspace(np.log10(Z.min()), np.log10(Z.max()), 20)\n",
    "    ax.contour(Z,  levels=clevels[1::2], colors=\"white\", linestyles=\"dashed\", alpha=0.25)\n",
    "    ax.contour(Z,  levels=clevels[::2], colors=\"black\", linestyles=\"dashed\", alpha=0.25)\n",
    "\n",
    "    if i%COLS == 0:\n",
    "        ax.set_ylabel(idx[0]+\"\\n\\nBudget\")\n",
    "        ticks = [0, 10, 20]\n",
    "        ax.set_yticks(ticks, minor=False)\n",
    "        labels = [\"$2^{\"+str(x+5)+\"}$\" for x in ticks]\n",
    "        ax.set_yticklabels(labels, fontdict=None, minor=False)\n",
    "    else:\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    if i//COLS != 6:\n",
    "        ax.xaxis.set_visible(False)\n",
    "\n",
    "    if i//COLS == 0:\n",
    "        ax.set_title(idx[1])\n",
    "        \n",
    "    if i//COLS == 6:\n",
    "        labels = [0,1,2,3]\n",
    "        ticks = [np.abs(x_axes-i).argmin() for i in [0,1,2,3]]\n",
    "        ax.set_xticks(ticks, minor=False)\n",
    "        labels = [\"$10^{\"+str(x)+\"}$\" for x in labels]\n",
    "        ax.set_xticklabels(labels, fontdict=None, minor=False)\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "#fig.colorbar(pcm, ax=axs, location='right', shrink=0.6)\n",
    "plt.suptitle(\"Average Log Validation Loss for all Depths\")\n",
    "#plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-fitting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_string = f'''\n",
    "select \"config.budget\", avg(a.val) as value, count(a.val), a.epoch, \"config.dataset\", \"config.depth\"\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.history_val_loss) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\"='fixed_01' and\n",
    "    \"config.topology\"='rectangle' and\n",
    "    \"config.residual_mode\"='none' and\n",
    "    \"config.depth\" IN (2, 4, 8, 16)\n",
    "GROUP BY epoch, \"config.budget\", \"config.dataset\", \"config.depth\"\n",
    "'''\n",
    "df = cached_query(query_string)\n",
    "\n",
    "df[\"log_epoch\"] = np.log10((df[\"epoch\"]))\n",
    "\n",
    "df[\"value\"] = np.log(df[\"value\"])\n",
    "\n",
    "x_axes = np.linspace(df[\"log_epoch\"].min(), df[\"log_epoch\"].max(), 500)\n",
    "\n",
    "ROWS = 7\n",
    "COLS = 4\n",
    "\n",
    "fig, axs = plt.subplots(ROWS,COLS, figsize=(11,8), dpi=300, sharex=True)\n",
    "\n",
    "i = 0\n",
    "for idx, gdf in df.groupby([\"config.dataset\", \"config.depth\"]):\n",
    "    img = np.ndarray(shape=(22,500))\n",
    "    \n",
    "    \n",
    "#     value_min = gdf[\"value\"].min()\n",
    "#     value_max = gdf[\"value\"].max()\n",
    "    \n",
    "    value_min = df[df[\"config.dataset\"]==idx[0]][\"value\"].min()\n",
    "    value_max = df[df[\"config.dataset\"]==idx[0]][\"value\"].max()\n",
    "    \n",
    "    v_range = value_max - value_min\n",
    "\n",
    "    for row_idx, row_df in gdf.groupby(\"config.budget\"):\n",
    "        \n",
    "        color_scale = 0.2\n",
    "        \n",
    "        intp = scipy.interpolate.interp1d(row_df[\"log_epoch\"],\n",
    "                                          row_df[\"value\"],\n",
    "                                          kind='linear',\n",
    "                                          bounds_error=False)\n",
    "\n",
    "        row_idx = int(np.log2(row_idx)-5)\n",
    "        \n",
    "        vals = intp(x_axes)\n",
    "        vals = np.minimum(value_min+(v_range*color_scale), vals)\n",
    "        img[row_idx, :] = vals\n",
    "    \n",
    "    ax = axs[i//COLS, i%COLS]\n",
    "    pcm = ax.imshow(img, aspect=\"auto\", cmap=\"viridis_r\")#, vmin=value_min, vmax=value_max)\n",
    "    \n",
    "    X,Y = np.meshgrid(np.arange(0,500),np.arange(0, 22))\n",
    "    Z = np.power(10, x_axes[X])*np.power(2, Y+5)\n",
    "    \n",
    "    clevels = np.logspace(np.log10(Z.min()), np.log10(Z.max()), 20)\n",
    "    ax.contour(Z,  levels=clevels[1::2], colors=\"white\", linestyles=\"dashed\", alpha=0.25)\n",
    "    ax.contour(Z,  levels=clevels[::2], colors=\"black\", linestyles=\"dashed\", alpha=0.25)\n",
    "\n",
    "    if i%COLS == 0:\n",
    "        ax.set_ylabel(idx[0]+\"\\n\\nBudget\")\n",
    "        ticks = [0, 10, 20]\n",
    "        ax.set_yticks(ticks, minor=False)\n",
    "        labels = [\"$2^{\"+str(x+5)+\"}$\" for x in ticks]\n",
    "        ax.set_yticklabels(labels, fontdict=None, minor=False)\n",
    "    else:\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    if i//COLS != 6:\n",
    "        ax.xaxis.set_visible(False)\n",
    "\n",
    "    if i//COLS == 0:\n",
    "        ax.set_title(f\"Depth = {idx[1]}\")\n",
    "        \n",
    "    if i//COLS == 6:\n",
    "        labels = [0,1,2,3]\n",
    "        ticks = [np.abs(x_axes-i).argmin() for i in [0,1,2,3]]\n",
    "        ax.set_xticks(ticks, minor=False)\n",
    "        labels = [\"$10^{\"+str(x)+\"}$\" for x in labels]\n",
    "        ax.set_xticklabels(labels, fontdict=None, minor=False)\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "#fig.colorbar(pcm, ax=axs, location='right', shrink=0.6)\n",
    "plt.suptitle(\"Log Validation Loss for Rectangular Topology and Various Depths\")\n",
    "#plt.tight_layout()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-witness",
   "metadata": {},
   "source": [
    "# Effect of Residual on one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Diff with topologies\n",
    "\n",
    "@interact_manual(**options, viz=[\"imshow\", \"scatter\"])\n",
    "def heatmap_app(groups=\"('fixed_01')\", depth=16, dataset=\"201_pol\", topology=\"rectangle\", loss=\"history_val_loss\", agg=\"avg\", viz=\"imshow\"):\n",
    "    query_string = f'''\n",
    "select \"config.budget\", {agg}(a.val) as value, count(a.val), a.epoch, \"config.residual_mode\"\n",
    "from\n",
    "    materialized_experiments_0 t,\n",
    "    unnest(t.{loss}) WITH ORDINALITY as a(val, epoch)\n",
    "WHERE\n",
    "    \"groupname\" IN {groups} and\n",
    "    \"config.dataset\"='{dataset}' and\n",
    "    \"config.topology\"='{topology}' and\n",
    "    \"config.depth\"={depth}\n",
    "GROUP BY epoch, \"config.budget\", \"config.residual_mode\"\n",
    "'''\n",
    "    df = cached_query(query_string)\n",
    "    \n",
    "    #df = df.set_index([\"config.budget\", \"epoch\"])\n",
    "    \n",
    "    df = df.pivot_table(columns=\"config.residual_mode\", index=[\"config.budget\", \"epoch\"], values=\"value\")\n",
    "    \n",
    "    df[\"value\"] = ((df[\"none\"] - df[\"full\"])/df[\"none\"])*100\n",
    "        \n",
    "    img = df.pivot_table(columns=\"epoch\", index=\"config.budget\", values=\"value\")\n",
    "    img.index = img.index.astype(\"str\") #plotly interprets the y axis as numeric otherwise\n",
    "    \n",
    "    zmax = np.maximum(np.abs(df[\"value\"].min()), np.abs(df[\"value\"].max()))\n",
    "    \n",
    "    return px.imshow(img, zmin=-zmax, zmax=zmax,\n",
    "                     color_continuous_scale=\"inferno\",\n",
    "                     title=f\"Percent Improvement in Validation Loss for Residual Networks. Dataset={dataset}, depth={depth}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-channels",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
