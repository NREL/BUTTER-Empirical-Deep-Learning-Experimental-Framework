{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 15:26:06.308339: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-15 15:26:06.328850: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-15 15:26:06.328869: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-15 15:26:06.328882: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-15 15:26:06.333002: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-15 15:26:06.333687: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-15 15:26:06.814026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy\n",
    "import pandas\n",
    "import io\n",
    "import uuid\n",
    "import psycopg.sql\n",
    "import pyarrow\n",
    "import pyarrow.parquet\n",
    "\n",
    "import jobqueue\n",
    "from jobqueue.connection_manager import ConnectionManager\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from typing import Callable, List\n",
    "\n",
    "from psycopg import sql\n",
    "\n",
    "import dmp.keras_interface.model_serialization as model_serialization\n",
    "from dmp.task.experiment.training_experiment.training_epoch import TrainingEpoch\n",
    "from dmp.postgres_interface.element.column import Column\n",
    "from dmp.postgres_interface.element.table import Table\n",
    "from dmp.postgres_interface.element.column_group import ColumnGroup\n",
    "\n",
    "from dmp.util.butter_e_export import *\n",
    "\n",
    "pd.options.display.max_seq_items = None\n",
    "credentials = jobqueue.load_credentials(\"dmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch that minimizes: Column = Column(\"minimizes\", \"loss\") and the corresponding loss\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "  \"fit\": {\n",
    "    \"epochs\": 3000,\n",
    "    \"batch_size\": 256\n",
    "  },\n",
    "  \"loss\": null,\n",
    "  \"seed\": 1663277341,\n",
    "  \"type\": \"TrainingExperiment\",\n",
    "  \"batch\": \"energy_1\",\n",
    "  \"model\": {\n",
    "    \"size\": 2048,\n",
    "    \"type\": \"DenseBySize\",\n",
    "    \"depth\": 4,\n",
    "    \"inner\": {\n",
    "      \"type\": \"Dense\",\n",
    "      \"units\": -1,\n",
    "      \"use_bias\": true,\n",
    "      \"activation\": \"relu\",\n",
    "      \"bias_constraint\": null,\n",
    "      \"bias_initializer\": \"Zeros\",\n",
    "      \"bias_regularizer\": null,\n",
    "      \"kernel_constraint\": null,\n",
    "      \"kernel_initializer\": \"GlorotUniform\",\n",
    "      \"kernel_regularizer\": null,\n",
    "      \"activity_regularizer\": null\n",
    "    },\n",
    "    \"input\": null,\n",
    "    \"shape\": \"exponential\",\n",
    "    \"output\": null,\n",
    "    \"search_method\": \"integer\"\n",
    "  },\n",
    "  \"record\": {\n",
    "    \"type\": \"ExperimentRecordSettings\",\n",
    "    \"model\": null,\n",
    "    \"times\": false,\n",
    "    \"metrics\": null,\n",
    "    \"post_training_metrics\": false\n",
    "  },\n",
    "  \"dataset\": {\n",
    "    \"name\": \"201_pol\",\n",
    "    \"type\": \"DatasetSpec\",\n",
    "    \"method\": \"shuffled_train_test_split\",\n",
    "    \"source\": \"pmlb\",\n",
    "    \"test_split\": 0.2,\n",
    "    \"label_noise\": 0,\n",
    "    \"validation_split\": 0\n",
    "  },\n",
    "  \"run_tags\": null,\n",
    "  \"optimizer\": {\n",
    "    \"class\": \"Adam\",\n",
    "    \"learning_rate\": 0.0001\n",
    "  },\n",
    "  \"precision\": \"float32\",\n",
    "  \"early_stopping\": null\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run vars {'_name': 'run', '_columns': (), '_index': None}\n",
      "('experiment_id', 'run_timestamp', 'run_id', 'job_id', 'seed', 'slurm_job_id', 'task_version', 'num_nodes', 'num_cpus', 'num_gpus', 'gpu_memory', 'host_name', 'batch', 'run_data', 'run_history', 'run_extended_history', 'queue', 'status', 'priority', 'start_time', 'update_time', 'worker', 'error_count', 'error', 'parent', 'command')\n",
      "{Column(_name='experiment_id', type_name='uuid'): 0, Column(_name='run_timestamp', type_name='timestamp'): 1, Column(_name='run_id', type_name='uuid'): 2, Column(_name='job_id', type_name='uuid'): 3, Column(_name='seed', type_name='bigint'): 4, Column(_name='slurm_job_id', type_name='bigint'): 5, Column(_name='task_version', type_name='smallint'): 6, Column(_name='num_nodes', type_name='smallint'): 7, Column(_name='num_cpus', type_name='smallint'): 8, Column(_name='num_gpus', type_name='smallint'): 9, Column(_name='gpu_memory', type_name='integer'): 10, Column(_name='host_name', type_name='text'): 11, Column(_name='batch', type_name='text'): 12, Column(_name='run_data', type_name='jsonb'): 13, Column(_name='run_history', type_name='bytea'): 14, Column(_name='run_extended_history', type_name='bytea'): 15, Column(_name='queue', type_name='smallint'): 16, Column(_name='status', type_name='smallint'): 17, Column(_name='priority', type_name='integer'): 18, Column(_name='start_time', type_name='timestamp'): 19, Column(_name='update_time', type_name='timestamp'): 20, Column(_name='worker', type_name='uuid'): 21, Column(_name='error_count', type_name='smallint'): 22, Column(_name='error', type_name='text'): 23, Column(_name='parent', type_name='uuid'): 24, Column(_name='command', type_name='jsonb'): 25}\n",
      "{Column(_name='experiment_id', type_name='uuid'): 0, Column(_name='run_timestamp', type_name='timestamp'): 1, Column(_name='run_id', type_name='uuid'): 2, Column(_name='job_id', type_name='uuid'): 3, Column(_name='seed', type_name='bigint'): 4, Column(_name='slurm_job_id', type_name='bigint'): 5, Column(_name='task_version', type_name='smallint'): 6, Column(_name='num_nodes', type_name='smallint'): 7, Column(_name='num_cpus', type_name='smallint'): 8, Column(_name='num_gpus', type_name='smallint'): 9, Column(_name='gpu_memory', type_name='integer'): 10, Column(_name='host_name', type_name='text'): 11, Column(_name='batch', type_name='text'): 12, Column(_name='run_data', type_name='jsonb'): 13, Column(_name='run_history', type_name='bytea'): 14, Column(_name='run_extended_history', type_name='bytea'): 15, Column(_name='queue', type_name='smallint'): 16, Column(_name='status', type_name='smallint'): 17, Column(_name='priority', type_name='integer'): 18, Column(_name='start_time', type_name='timestamp'): 19, Column(_name='update_time', type_name='timestamp'): 20, Column(_name='worker', type_name='uuid'): 21, Column(_name='error_count', type_name='smallint'): 22, Column(_name='error', type_name='text'): 23, Column(_name='parent', type_name='uuid'): 24, Column(_name='command', type_name='jsonb'): 25}\n",
      "{Column(_name='experiment_id', type_name='uuid'): 0, Column(_name='run_timestamp', type_name='timestamp'): 1, Column(_name='run_id', type_name='uuid'): 2, Column(_name='job_id', type_name='uuid'): 3, Column(_name='seed', type_name='bigint'): 4, Column(_name='slurm_job_id', type_name='bigint'): 5, Column(_name='task_version', type_name='smallint'): 6, Column(_name='num_nodes', type_name='smallint'): 7, Column(_name='num_cpus', type_name='smallint'): 8, Column(_name='num_gpus', type_name='smallint'): 9, Column(_name='gpu_memory', type_name='integer'): 10, Column(_name='host_name', type_name='text'): 11, Column(_name='batch', type_name='text'): 12, Column(_name='run_data', type_name='jsonb'): 13, Column(_name='run_history', type_name='bytea'): 14, Column(_name='run_extended_history', type_name='bytea'): 15, Column(_name='queue', type_name='smallint'): 16, Column(_name='status', type_name='smallint'): 17, Column(_name='priority', type_name='integer'): 18, Column(_name='start_time', type_name='timestamp'): 19, Column(_name='update_time', type_name='timestamp'): 20, Column(_name='worker', type_name='uuid'): 21, Column(_name='error_count', type_name='smallint'): 22, Column(_name='error', type_name='text'): 23, Column(_name='parent', type_name='uuid'): 24, Column(_name='command', type_name='jsonb'): 25}\n",
      "{Column(_name='experiment_id', type_name='uuid'): 0, Column(_name='run_timestamp', type_name='timestamp'): 1, Column(_name='run_id', type_name='uuid'): 2, Column(_name='job_id', type_name='uuid'): 3, Column(_name='seed', type_name='bigint'): 4, Column(_name='slurm_job_id', type_name='bigint'): 5, Column(_name='task_version', type_name='smallint'): 6, Column(_name='num_nodes', type_name='smallint'): 7, Column(_name='num_cpus', type_name='smallint'): 8, Column(_name='num_gpus', type_name='smallint'): 9, Column(_name='gpu_memory', type_name='integer'): 10, Column(_name='host_name', type_name='text'): 11, Column(_name='batch', type_name='text'): 12, Column(_name='run_data', type_name='jsonb'): 13, Column(_name='run_history', type_name='bytea'): 14, Column(_name='run_extended_history', type_name='bytea'): 15, Column(_name='queue', type_name='smallint'): 16, Column(_name='status', type_name='smallint'): 17, Column(_name='priority', type_name='integer'): 18, Column(_name='start_time', type_name='timestamp'): 19, Column(_name='update_time', type_name='timestamp'): 20, Column(_name='worker', type_name='uuid'): 21, Column(_name='error_count', type_name='smallint'): 22, Column(_name='error', type_name='text'): 23, Column(_name='parent', type_name='uuid'): 24, Column(_name='command', type_name='jsonb'): 25}\n",
      "\n",
      "SELECT\n",
      "\t\"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "FROM\n",
      "\t\"run\",\n",
      "\t\"job_status\",\n",
      "\t\"job_data\"\n",
      "WHERE TRUE\n",
      "\tAND \"run\".batch like '%energy%'\n",
      "\tAND \"job_status\".id = \"run\".run_id\n",
      "\tAND \"job_status\".id = \"job_data\".id\n",
      "    AND \"job_status\".status = 2\n",
      "ORDER BY experiment_id, run_id\n",
      "LIMIT 10;\n",
      "\n",
      "   test_mean_squared_error  train_mean_squared_error  test_loss  train_loss  \\\n",
      "0                 0.018292                  0.018138   0.018292    0.018138   \n",
      "1                 0.017241                  0.016899   0.017241    0.016899   \n",
      "2                 0.016371                  0.015950   0.016371    0.015950   \n",
      "3                 0.015637                  0.015154   0.015637    0.015154   \n",
      "4                 0.015003                  0.014478   0.015003    0.014478   \n",
      "\n",
      "   epoch  test_cosine_similarity  train_cosine_similarity  \\\n",
      "0      1                     1.0                 0.999675   \n",
      "1      2                     1.0                 0.999675   \n",
      "2      3                     1.0                 0.999675   \n",
      "3      4                     1.0                 0.999675   \n",
      "4      5                     1.0                 0.999675   \n",
      "\n",
      "   test_kullback_leibler_divergence  train_kullback_leibler_divergence  \\\n",
      "0                          0.018892                           0.018794   \n",
      "1                          0.017697                           0.016923   \n",
      "2                          0.016885                           0.016182   \n",
      "3                          0.016182                           0.015660   \n",
      "4                          0.015552                           0.015219   \n",
      "\n",
      "   test_root_mean_squared_error  ...  run_tags  class  learning_rate  \\\n",
      "0                      0.131305  ...      None   Adam         0.0001   \n",
      "1                      0.127949  ...      None   Adam         0.0001   \n",
      "2                      0.125047  ...      None   Adam         0.0001   \n",
      "3                      0.122488  ...      None   Adam         0.0001   \n",
      "4                      0.120194  ...      None   Adam         0.0001   \n",
      "\n",
      "   early_stopping  test_accuracy  train_accuracy test_hinge train_hinge  \\\n",
      "0            None            NaN             NaN        NaN         NaN   \n",
      "1            None            NaN             NaN        NaN         NaN   \n",
      "2            None            NaN             NaN        NaN         NaN   \n",
      "3            None            NaN             NaN        NaN         NaN   \n",
      "4            None            NaN             NaN        NaN         NaN   \n",
      "\n",
      "  test_squared_hinge train_squared_hinge  \n",
      "0                NaN                 NaN  \n",
      "1                NaN                 NaN  \n",
      "2                NaN                 NaN  \n",
      "3                NaN                 NaN  \n",
      "4                NaN                 NaN  \n",
      "\n",
      "[5 rows x 91 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1595: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1596: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1596: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "from psycopg import ClientCursor\n",
    "\n",
    "\n",
    "print(f\"run vars {vars(run)}\")\n",
    "\n",
    "columns = (\n",
    "    run\n",
    "    + ColumnGroup(*[c for c in job_status.columns if c.name != \"id\"])\n",
    "    + job_data.command\n",
    ")\n",
    "print(columns.names)\n",
    "\n",
    "\n",
    "def passthrough(row, index, value, column, data):\n",
    "    data[column.name] = value\n",
    "\n",
    "\n",
    "column_converters: List[Callable] = [passthrough for _ in columns]\n",
    "\n",
    "\n",
    "def flatten_json(json_obj, destination=None, parent_key=\"\", separator=\"_\"):\n",
    "    if isinstance(destination, dict):\n",
    "        flattened = destination\n",
    "    else:\n",
    "        flattened = {}\n",
    "\n",
    "    for key, value in json_obj.items():\n",
    "        new_key = f\"{parent_key}{separator}{key}\" if parent_key else key\n",
    "        if isinstance(value, dict):\n",
    "            flattened.update(flatten_json(value, new_key, separator=separator))\n",
    "        else:\n",
    "            flattened[new_key] = value\n",
    "    return flattened\n",
    "\n",
    "\n",
    "column_converters[\n",
    "    columns.get_index_of(job_data.command)\n",
    "] = lambda row, index, value, column, data: flatten_json(value, destination=data)\n",
    "column_converters[\n",
    "    columns.get_index_of(run.run_data)\n",
    "] = lambda row, index, value, column, data: flatten_json(value, destination=data)\n",
    "\n",
    "\n",
    "def parquet_to_dataframe(row, index, value, column, data):\n",
    "    with io.BytesIO(value) as buffer:\n",
    "        data[column.name] = (\n",
    "            pyarrow.parquet.read_table(pyarrow.PythonFile(buffer, mode=\"r\"))\n",
    "            .to_pandas()\n",
    "            .sort_values(by=\"epoch\")\n",
    "        )\n",
    "\n",
    "\n",
    "column_converters[columns.get_index_of(run.run_history)] = parquet_to_dataframe\n",
    "column_converters[columns.get_index_of(run.run_extended_history)] = parquet_to_dataframe\n",
    "\n",
    "\n",
    "dfs = []\n",
    "\n",
    "with ConnectionManager(credentials) as connection:\n",
    "    \"\"\"\n",
    "    TODO: convert this into two steps:\n",
    "    1) Get the ids of the runs we want to extract (in energy batches) ordered by experiment_id\n",
    "\n",
    "          SELECT\n",
    "                  {run}.{run_id}\n",
    "          FROM\n",
    "                  {run},\n",
    "                  {job_status},\n",
    "                  {job_data}\n",
    "          WHERE TRUE\n",
    "                  AND {run}.batch like {pattern}\n",
    "                  AND {job_status}.id = {run}.run_id\n",
    "                  AND {job_status}.id = {job_data}.id\n",
    "              AND {job_status}.status = 2\n",
    "          ORDER BY experiment_id, run_id;\n",
    "\n",
    "    2) In parallel (using the multiprocessing lib), extract blocks of ids into a partitioned parquet file\n",
    "      -> partition by the attributes we care about querying by (dataset, size, shape, depth)\n",
    "\n",
    "              SELECT\n",
    "                  {columns}\n",
    "              FROM\n",
    "                  {run},\n",
    "                  {job_status},\n",
    "                  {job_data}\n",
    "              WHERE TRUE\n",
    "                  AND {job_status}.id = {run}.run_id\n",
    "                  AND {job_status}.id = {job_data}.id\n",
    "                  AND {job_status}.status = 2\n",
    "                  AND {run}.{run_id} IN ({ids})\n",
    "\n",
    "        pool = multiprocessing.ProcessPool(multiprocessing.cpu_count())\n",
    "        results = pool.uimap(download_chunk, chunks)\n",
    "        for num_rows, chunk in results:\n",
    "            num_stored += 1\n",
    "            print(f\"Stored {num_rows} in chunk {chunk}, {num_stored} / {len(chunks)}.\")\n",
    "\n",
    "    extra credit) extract butter data matching this as well into a new dataset\n",
    "    extra credit) make a summary dataset that summarizes the quartiles of # epochs to reach target test loss levels\n",
    "\n",
    "    getting a few attrs from the energy runs:\n",
    "    SELECT\n",
    "        size,\n",
    "        depth,\n",
    "        shape,\n",
    "        dataset,\n",
    "        learning_rate,\n",
    "        batch_size,\n",
    "        optimizer,\n",
    "        COUNT(1) num,\n",
    "        SUM(is_cpu) num_cpu,\n",
    "        (COUNT(1) - SUM(is_cpu)) num_gpu\n",
    "    FROM\n",
    "    (\n",
    "            SELECT\n",
    "                    slurm_job_id,\n",
    "                    start_time,\n",
    "                    update_time end_time,\n",
    "                    (command->'model'->'size')::int size,\n",
    "                    (command->'model'->'depth')::int depth,\n",
    "                    (command->'model'->>'shape')::text shape,\n",
    "                    (command->'dataset'->>'name')::text dataset,\n",
    "                    (command->'optimizer'->'learning_rate')::float learning_rate,\n",
    "                    (command->'fit'->'batch_size')::int batch_size,\n",
    "                    (command->'optimizer'->>'class')::text optimizer,\n",
    "                    (num_gpus <= 0)::int is_cpu\n",
    "            FROM\n",
    "                    run,\n",
    "                    job_status,\n",
    "                    job_data\n",
    "            WHERE TRUE\n",
    "                    AND run.batch like '%energy%'\n",
    "                    AND job_status.id = run.run_id\n",
    "                    AND job_status.id = job_data.id\n",
    "                    AND job_status.status = 2\n",
    "    ) x\n",
    "    WHERE TRUE\n",
    "            AND depth = 5\n",
    "            AND shape = 'rectangle'\n",
    "            AND dataset = 'sleep'\n",
    "    GROUP BY\n",
    "            learning_rate,\n",
    "            batch_size,\n",
    "            optimizer,\n",
    "            depth,\n",
    "            shape,\n",
    "            dataset,\n",
    "            size\n",
    "    ORDER BY\n",
    "            learning_rate,\n",
    "            batch_size,\n",
    "            optimizer,\n",
    "            depth,\n",
    "            shape,\n",
    "            dataset,\n",
    "            size\n",
    "    ;\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    query = psycopg.sql.SQL(\n",
    "        \"\"\"\n",
    "SELECT\n",
    "\t{columns}\n",
    "FROM\n",
    "\t{run},\n",
    "\t{job_status},\n",
    "\t{job_data}\n",
    "WHERE TRUE\n",
    "\tAND {run}.batch like {pattern}\n",
    "\tAND {job_status}.id = {run}.run_id\n",
    "\tAND {job_status}.id = {job_data}.id\n",
    "    AND {job_status}.status = 2\n",
    "ORDER BY experiment_id, run_id\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "    ).format(\n",
    "        columns=columns.columns_sql,\n",
    "        run=run.identifier,\n",
    "        job_status=job_status.identifier,\n",
    "        job_data=job_data.identifier,\n",
    "        pattern=sql.Literal(\"%energy%\"),\n",
    "    )\n",
    "\n",
    "    with ClientCursor(connection) as c:\n",
    "        print(c.mogrify(query))\n",
    "\n",
    "    with connection.cursor(binary=True) as cursor:\n",
    "        cursor.execute(query, binary=True)\n",
    "\n",
    "        for row in cursor:\n",
    "            row_data = {}\n",
    "            for i, (column, column_converter) in enumerate(\n",
    "                zip(columns, column_converters)\n",
    "            ):\n",
    "                column_converter(row, i, row[i], column, row_data)\n",
    "\n",
    "            row_df = row_data[\"run_history\"]\n",
    "            row_df = row_df.join(\n",
    "                row_data[\"run_extended_history\"], on=\"epoch\", how=\"left\", rsuffix=\"_\"\n",
    "            )\n",
    "            for k in (\"run_history\", \"run_extended_history\"):\n",
    "                del row_data[k]\n",
    "\n",
    "            for k, v in row_data.items():\n",
    "                if k in row_df:\n",
    "                    pass\n",
    "                if isinstance(v, list):\n",
    "                    row_df[k] = [v] * len(row_df)\n",
    "                else:\n",
    "                    row_df[k] = v\n",
    "                # data.setdefault(k, []).append(v)\n",
    "            dfs.append(row_df)\n",
    "\n",
    "data = pandas.concat(dfs)\n",
    "del dfs\n",
    "\n",
    "data.describe()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['test_mean_squared_error', 'train_mean_squared_error', 'test_loss',\n",
       "       'train_loss', 'epoch', 'test_cosine_similarity',\n",
       "       'train_cosine_similarity', 'test_kullback_leibler_divergence',\n",
       "       'train_kullback_leibler_divergence', 'test_root_mean_squared_error',\n",
       "       'train_root_mean_squared_error', 'test_mean_absolute_error',\n",
       "       'train_mean_absolute_error', 'test_mean_squared_logarithmic_error',\n",
       "       'train_mean_squared_logarithmic_error', 'epoch_', 'experiment_id',\n",
       "       'run_timestamp', 'run_id', 'job_id', 'seed', 'slurm_job_id',\n",
       "       'task_version', 'num_nodes', 'num_cpus', 'num_gpus', 'gpu_memory',\n",
       "       'host_name', 'batch', 'cpus', 'gpus', 'nodes', 'git_hash', 'platform',\n",
       "       'strategy', 'precision', 'record_model', 'record_times',\n",
       "       'python_version', 'record_metrics', 'tensorflow_version',\n",
       "       'record_post_training_metrics', 'queue', 'status', 'priority',\n",
       "       'start_time', 'update_time', 'worker', 'error_count', 'error', 'parent',\n",
       "       'epochs', 'batch_size', 'loss', 'type', 'size', 'depth', 'units',\n",
       "       'use_bias', 'activation', 'bias_constraint', 'bias_initializer',\n",
       "       'bias_regularizer', 'kernel_constraint', 'kernel_initializer',\n",
       "       'kernel_regularizer', 'activity_regularizer', 'input', 'shape',\n",
       "       'output', 'search_method', 'model', 'times', 'metrics',\n",
       "       'post_training_metrics', 'name', 'method', 'source', 'test_split',\n",
       "       'label_noise', 'validation_split', 'run_tags', 'class', 'learning_rate',\n",
       "       'early_stopping', 'test_accuracy', 'train_accuracy', 'test_hinge',\n",
       "       'train_hinge', 'test_squared_hinge', 'train_squared_hinge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1595: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1596: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1596: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1595: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1596: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1596: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_mean_squared_error</th>\n",
       "      <th>train_mean_squared_error</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>test_cosine_similarity</th>\n",
       "      <th>train_cosine_similarity</th>\n",
       "      <th>test_kullback_leibler_divergence</th>\n",
       "      <th>train_kullback_leibler_divergence</th>\n",
       "      <th>test_root_mean_squared_error</th>\n",
       "      <th>...</th>\n",
       "      <th>run_tags</th>\n",
       "      <th>class</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_hinge</th>\n",
       "      <th>train_hinge</th>\n",
       "      <th>test_squared_hinge</th>\n",
       "      <th>train_squared_hinge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018292</td>\n",
       "      <td>0.018138</td>\n",
       "      <td>0.018292</td>\n",
       "      <td>1.813805e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>1.879420e-02</td>\n",
       "      <td>0.131305</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.016899</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>1.689905e-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.017697</td>\n",
       "      <td>1.692268e-02</td>\n",
       "      <td>0.127949</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016371</td>\n",
       "      <td>0.015950</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>1.594961e-02</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>1.618220e-02</td>\n",
       "      <td>0.125047</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015637</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.015637</td>\n",
       "      <td>1.515436e-02</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.016182</td>\n",
       "      <td>1.565967e-02</td>\n",
       "      <td>0.122488</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015003</td>\n",
       "      <td>0.014478</td>\n",
       "      <td>0.015003</td>\n",
       "      <td>1.447835e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.015552</td>\n",
       "      <td>1.521902e-02</td>\n",
       "      <td>0.120194</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437851</td>\n",
       "      <td>2.128737e-11</td>\n",
       "      <td>2996</td>\n",
       "      <td>0.984514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209813</td>\n",
       "      <td>2.122752e-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>0.984429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437654</td>\n",
       "      <td>2.128737e-11</td>\n",
       "      <td>2997</td>\n",
       "      <td>0.984507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209817</td>\n",
       "      <td>2.117616e-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>0.984429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437477</td>\n",
       "      <td>2.128737e-11</td>\n",
       "      <td>2998</td>\n",
       "      <td>0.984497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209831</td>\n",
       "      <td>2.113641e-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437325</td>\n",
       "      <td>2.128737e-11</td>\n",
       "      <td>2999</td>\n",
       "      <td>0.984484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209855</td>\n",
       "      <td>2.110676e-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437192</td>\n",
       "      <td>2.128737e-11</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_mean_squared_error  train_mean_squared_error  test_loss  \\\n",
       "0                    0.018292                  0.018138   0.018292   \n",
       "1                    0.017241                  0.016899   0.017241   \n",
       "2                    0.016371                  0.015950   0.016371   \n",
       "3                    0.015637                  0.015154   0.015637   \n",
       "4                    0.015003                  0.014478   0.015003   \n",
       "...                       ...                       ...        ...   \n",
       "2995                      NaN                       NaN   0.437851   \n",
       "2996                      NaN                       NaN   0.437654   \n",
       "2997                      NaN                       NaN   0.437477   \n",
       "2998                      NaN                       NaN   0.437325   \n",
       "2999                      NaN                       NaN   0.437192   \n",
       "\n",
       "        train_loss  epoch  test_cosine_similarity  train_cosine_similarity  \\\n",
       "0     1.813805e-02      1                1.000000                 0.999675   \n",
       "1     1.689905e-02      2                1.000000                 0.999675   \n",
       "2     1.594961e-02      3                1.000000                 0.999675   \n",
       "3     1.515436e-02      4                1.000000                 0.999675   \n",
       "4     1.447835e-02      5                1.000000                 0.999675   \n",
       "...            ...    ...                     ...                      ...   \n",
       "2995  2.128737e-11   2996                0.984514                 1.000000   \n",
       "2996  2.128737e-11   2997                0.984507                 1.000000   \n",
       "2997  2.128737e-11   2998                0.984497                 1.000000   \n",
       "2998  2.128737e-11   2999                0.984484                 1.000000   \n",
       "2999  2.128737e-11   3000                     NaN                      NaN   \n",
       "\n",
       "      test_kullback_leibler_divergence  train_kullback_leibler_divergence  \\\n",
       "0                             0.018892                       1.879420e-02   \n",
       "1                             0.017697                       1.692268e-02   \n",
       "2                             0.016885                       1.618220e-02   \n",
       "3                             0.016182                       1.565967e-02   \n",
       "4                             0.015552                       1.521902e-02   \n",
       "...                                ...                                ...   \n",
       "2995                          0.209813                       2.122752e-11   \n",
       "2996                          0.209817                       2.117616e-11   \n",
       "2997                          0.209831                       2.113641e-11   \n",
       "2998                          0.209855                       2.110676e-11   \n",
       "2999                               NaN                                NaN   \n",
       "\n",
       "      test_root_mean_squared_error  ...  run_tags  class  learning_rate  \\\n",
       "0                         0.131305  ...      None   Adam         0.0001   \n",
       "1                         0.127949  ...      None   Adam         0.0001   \n",
       "2                         0.125047  ...      None   Adam         0.0001   \n",
       "3                         0.122488  ...      None   Adam         0.0001   \n",
       "4                         0.120194  ...      None   Adam         0.0001   \n",
       "...                            ...  ...       ...    ...            ...   \n",
       "2995                           NaN  ...      None   Adam         0.0001   \n",
       "2996                           NaN  ...      None   Adam         0.0001   \n",
       "2997                           NaN  ...      None   Adam         0.0001   \n",
       "2998                           NaN  ...      None   Adam         0.0001   \n",
       "2999                           NaN  ...      None   Adam         0.0001   \n",
       "\n",
       "      early_stopping  test_accuracy  train_accuracy test_hinge train_hinge  \\\n",
       "0               None            NaN             NaN        NaN         NaN   \n",
       "1               None            NaN             NaN        NaN         NaN   \n",
       "2               None            NaN             NaN        NaN         NaN   \n",
       "3               None            NaN             NaN        NaN         NaN   \n",
       "4               None            NaN             NaN        NaN         NaN   \n",
       "...              ...            ...             ...        ...         ...   \n",
       "2995            None       0.984429             1.0        NaN         NaN   \n",
       "2996            None       0.984429             1.0        NaN         NaN   \n",
       "2997            None       0.984286             1.0        NaN         NaN   \n",
       "2998            None       0.984286             1.0        NaN         NaN   \n",
       "2999            None       0.984286             1.0        NaN         NaN   \n",
       "\n",
       "     test_squared_hinge train_squared_hinge  \n",
       "0                   NaN                 NaN  \n",
       "1                   NaN                 NaN  \n",
       "2                   NaN                 NaN  \n",
       "3                   NaN                 NaN  \n",
       "4                   NaN                 NaN  \n",
       "...                 ...                 ...  \n",
       "2995                NaN                 NaN  \n",
       "2996                NaN                 NaN  \n",
       "2997                NaN                 NaN  \n",
       "2998                NaN                 NaN  \n",
       "2999                NaN                 NaN  \n",
       "\n",
       "[30000 rows x 91 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
