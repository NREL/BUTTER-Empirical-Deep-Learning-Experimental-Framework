{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy\n",
    "import pandas\n",
    "import io\n",
    "import uuid\n",
    "import psycopg.sql\n",
    "import pyarrow\n",
    "\n",
    "import jobqueue\n",
    "from jobqueue.connection_manager import ConnectionManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from enum import Enum, auto\n",
    "\n",
    "# class ColumnSource(Enum):\n",
    "#     run_column=auto()\n",
    "#     run\n",
    "#     run_column=auto()\n",
    "#     run_column=auto()\n",
    "#     run_column=auto()\n",
    "#     run_column=auto()\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Column:\n",
    "    name : str\n",
    "    pandas_type : str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "Name: run_data, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_columns = [\n",
    "    ('run_timestamp', 'datetime'),\n",
    "    ('run_id', 'uuid'),\n",
    "    ('job_id', 'uuid'),\n",
    "    ('seed' 'int64'),\n",
    "    ('slurm_job_id', 'str'),\n",
    "    ('task_version', 'int16'),\n",
    "    ('num_nodes', 'int16'),\n",
    "    ('num_cpus', 'int16'),\n",
    "    ('num_gpus', 'int16'),\n",
    "    ('gpu_memory', 'int32'),\n",
    "    ('host_name', 'str'),\n",
    "    ('batch', 'str'),\n",
    "    ('run_data', 'object'),\n",
    "    ('run_history', 'object'),\n",
    "    ('run_extended_history', 'object'),\n",
    "]\n",
    "\n",
    "experiment_columns = [\n",
    "    # experiment columns\n",
    "    ('experiment_id', 'uuid'),\n",
    "    ('experiment_attrs', 'integer[]'),\n",
    "    ('experiment_tags', 'integer[]'),\n",
    "    ('old_experiment_id', 'integer')\n",
    "]\n",
    "\n",
    "columns = [\n",
    "    ('e', 'experiment_id'),\n",
    "    ('e', 'old_experiment_id'),\n",
    "    ('experiment_attrs', 'experiment_attrs'),\n",
    "    ('r', 'run_id'),\n",
    "    ('r', 'job_id'),\n",
    "    ('r', 'slurm_job_id'),\n",
    "    ('r', 'run_timestamp'),\n",
    "    ('r', 'seed'),\n",
    "    ('r', 'task_version'),\n",
    "    ('r', 'num_nodes'),\n",
    "    ('r', 'num_cpus'),\n",
    "    ('r', 'num_gpus'),\n",
    "    ('r', 'gpu_memory'),\n",
    "    ('r', 'host_name'),\n",
    "    ('r', 'batch'),\n",
    "    ('r', 'run_data'),\n",
    "    ('r', 'run_history'),\n",
    "    ('r', 'run_extended_history'),\n",
    "    ('s', 'queue'),\n",
    "    ('s', 'status'),\n",
    "    ('s', 'priority'),\n",
    "    ('s', 'start_time'),\n",
    "    ('s', 'update_time'),\n",
    "    ('s', 'worker'),\n",
    "    ('s', 'error_count'),\n",
    "    ('d', 'command')\n",
    "]\n",
    "\n",
    "\n",
    "credentials = jobqueue.load_credentials('dmp')\n",
    "with ConnectionManager(credentials) as connection:\n",
    "    with connection.cursor(binary=True) as cursor:\n",
    "        query = psycopg.sql.SQL(\"\"\"\n",
    "SELECT\n",
    "    e.experiment_id,\n",
    "    e.old_experiment_id,\n",
    "    ea.experiment_attrs,\n",
    "    r.run_id,\n",
    "    r.job_id,\n",
    "    r.slurm_job_id,\n",
    "    r.run_timestamp,\n",
    "    r.seed,\n",
    "    r.task_version,\n",
    "    r.num_nodes,\n",
    "    r.num_cpus,\n",
    "    r.num_gpus,\n",
    "    r.gpu_memory,\n",
    "    r.host_name,\n",
    "    r.batch,\n",
    "    r.run_data,\n",
    "    r.run_history,\n",
    "    r.run_extended_history,\n",
    "    s.queue,\n",
    "    s.status,\n",
    "    s.priority,\n",
    "    s.start_time,\n",
    "    s.update_time,\n",
    "    s.worker,\n",
    "    s.error_count,\n",
    "    d.command\n",
    "FROM\n",
    "    run r,\n",
    "    experiment e,\n",
    "    job_status s,\n",
    "    job_data d,\n",
    "    lateral (\n",
    "        select\n",
    "            jsonb_object_agg(\n",
    "                a.kind,\n",
    "                coalesce(\n",
    "                    to_jsonb(a.value_bool),\n",
    "                    to_jsonb(a.value_int),\n",
    "                    to_jsonb(a.value_float),\n",
    "                    to_jsonb(a.value_str),\n",
    "                    to_jsonb(a.value_json)\n",
    "                )) experiment_attrs\n",
    "        FROM\n",
    "            (\n",
    "                SELECT attr_id FROM unnest(e.experiment_attrs) attr_id\n",
    "                UNION ALL\n",
    "                SELECT attr_id FROM unnest(e.experiment_tags) attr_id\n",
    "            )  attr_id\n",
    "            INNER JOIN attr a ON (a.attr_id = attr_id.attr_id)\n",
    "    ) ea\n",
    "WHERE TRUE\n",
    "    AND r.experiment_id = e.experiment_id\n",
    "    AND r.job_id = d.id\n",
    "    AND r.job_id = s.id\n",
    "    AND s.status = 2\n",
    "    AND jsonb_path_exists(r.run_data, '$.record_times[*] == true')\n",
    "    AND batch = 'make_batch_optimizer_butter_growth_eagle_gpu_1'\n",
    "    AND jsonb_path_exists(d.command, '$.tags.butter_growth[*] == true')\n",
    "    AND e.experiment_attrs && (\n",
    "        SELECT array_agg(attr_id)\n",
    "        FROM attr\n",
    "        WHERE kind = 'model_depth' and value_int < 5)\n",
    "    AND e.experiment_attrs @> (\n",
    "        SELECT array_agg(attr_id)\n",
    "        FROM attr\n",
    "        WHERE (kind = 'type' and value_str = 'GrowthExperiment')\n",
    "        OR (kind = 'classifier' and value_str = 'SGD')\n",
    "       )\n",
    "LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "        cursor.execute(query, binary=True)\n",
    "        data = {column: [] for source, column in columns}\n",
    "        for row_number, row in enumerate(cursor):\n",
    "            for i, (source, column) in enumerate(columns):\n",
    "                value = row[i]\n",
    "                if column in {'experiment_attrs', 'run_data'}:\n",
    "                    for kind, val in value.items():\n",
    "                        if kind not in data:\n",
    "                            data[kind] = [None] * row_number\n",
    "                        data[kind].append(val)\n",
    "                    continue\n",
    "                elif column == 'run_data':\n",
    "                    with io.BytesIO(value) as buffer:\n",
    "                        value = pyarrow.parquet.read_table(\n",
    "                            pyarrow.PythonFile(buffer, mode='r')).to_pandas()\n",
    "                \n",
    "                data[column].append(value)\n",
    "            for column in list(data.keys()):\n",
    "                while len(data[column]) < (row_number+1):\n",
    "                    data[column].append(None)\n",
    "\n",
    "        df = pandas.DataFrame(data=data)\n",
    "\n",
    "# df.describe()\n",
    "df['run_data'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
