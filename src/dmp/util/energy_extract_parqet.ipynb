{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 14:44:53.379727: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 14:44:53.549076: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-28 14:44:53.549098: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-28 14:44:53.549980: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-28 14:44:53.632516: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 14:44:53.633883: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-28 14:44:54.406508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy\n",
    "import pandas\n",
    "import io\n",
    "import uuid\n",
    "import psycopg.sql\n",
    "import pyarrow\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.parquet\n",
    "import jobqueue\n",
    "from jobqueue.connection_manager import ConnectionManager\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from typing import Callable, List\n",
    "\n",
    "from psycopg import sql\n",
    "\n",
    "import dmp.keras_interface.model_serialization as model_serialization\n",
    "from dmp.task.experiment.training_experiment.training_epoch import TrainingEpoch\n",
    "from dmp.postgres_interface.element.column import Column\n",
    "from dmp.postgres_interface.element.table import Table\n",
    "from dmp.postgres_interface.element.column_group import ColumnGroup\n",
    "\n",
    "from dmp.util.butter_e_export import *\n",
    "\n",
    "pd.options.display.max_seq_items = None\n",
    "credentials = jobqueue.load_credentials(\"dmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run vars {'_name': 'run', '_columns': (), '_index': None}\n",
      "('experiment_id', 'run_timestamp', 'run_id', 'job_id', 'seed', 'slurm_job_id', 'task_version', 'num_nodes', 'num_cpus', 'num_gpus', 'gpu_memory', 'host_name', 'batch', 'run_data', 'run_history', 'run_extended_history', 'queue', 'status', 'priority', 'start_time', 'update_time', 'worker', 'error_count', 'error', 'parent', 'command')\n",
      "{Column(_name='experiment_id', type_name='uuid'): 0, Column(_name='run_timestamp', type_name='timestamp'): 1, Column(_name='run_id', type_name='uuid'): 2, Column(_name='job_id', type_name='uuid'): 3, Column(_name='seed', type_name='bigint'): 4, Column(_name='slurm_job_id', type_name='bigint'): 5, Column(_name='task_version', type_name='smallint'): 6, Column(_name='num_nodes', type_name='smallint'): 7, Column(_name='num_cpus', type_name='smallint'): 8, Column(_name='num_gpus', type_name='smallint'): 9, Column(_name='gpu_memory', type_name='integer'): 10, Column(_name='host_name', type_name='text'): 11, Column(_name='batch', type_name='text'): 12, Column(_name='run_data', type_name='jsonb'): 13, Column(_name='run_history', type_name='bytea'): 14, Column(_name='run_extended_history', type_name='bytea'): 15, Column(_name='queue', type_name='smallint'): 16, Column(_name='status', type_name='smallint'): 17, Column(_name='priority', type_name='integer'): 18, Column(_name='start_time', type_name='timestamp'): 19, Column(_name='update_time', type_name='timestamp'): 20, Column(_name='worker', type_name='uuid'): 21, Column(_name='error_count', type_name='smallint'): 22, Column(_name='error', type_name='text'): 23, Column(_name='parent', type_name='uuid'): 24, Column(_name='command', type_name='jsonb'): 25}\n",
      "{Column(_name='experiment_id', type_name='uuid'): 0, Column(_name='run_timestamp', type_name='timestamp'): 1, Column(_name='run_id', type_name='uuid'): 2, Column(_name='job_id', type_name='uuid'): 3, Column(_name='seed', type_name='bigint'): 4, Column(_name='slurm_job_id', type_name='bigint'): 5, Column(_name='task_version', type_name='smallint'): 6, Column(_name='num_nodes', type_name='smallint'): 7, Column(_name='num_cpus', type_name='smallint'): 8, Column(_name='num_gpus', type_name='smallint'): 9, Column(_name='gpu_memory', type_name='integer'): 10, Column(_name='host_name', type_name='text'): 11, Column(_name='batch', type_name='text'): 12, Column(_name='run_data', type_name='jsonb'): 13, Column(_name='run_history', type_name='bytea'): 14, Column(_name='run_extended_history', type_name='bytea'): 15, Column(_name='queue', type_name='smallint'): 16, Column(_name='status', type_name='smallint'): 17, Column(_name='priority', type_name='integer'): 18, Column(_name='start_time', type_name='timestamp'): 19, Column(_name='update_time', type_name='timestamp'): 20, Column(_name='worker', type_name='uuid'): 21, Column(_name='error_count', type_name='smallint'): 22, Column(_name='error', type_name='text'): 23, Column(_name='parent', type_name='uuid'): 24, Column(_name='command', type_name='jsonb'): 25}\n",
      "{Column(_name='experiment_id', type_name='uuid'): 0, Column(_name='run_timestamp', type_name='timestamp'): 1, Column(_name='run_id', type_name='uuid'): 2, Column(_name='job_id', type_name='uuid'): 3, Column(_name='seed', type_name='bigint'): 4, Column(_name='slurm_job_id', type_name='bigint'): 5, Column(_name='task_version', type_name='smallint'): 6, Column(_name='num_nodes', type_name='smallint'): 7, Column(_name='num_cpus', type_name='smallint'): 8, Column(_name='num_gpus', type_name='smallint'): 9, Column(_name='gpu_memory', type_name='integer'): 10, Column(_name='host_name', type_name='text'): 11, Column(_name='batch', type_name='text'): 12, Column(_name='run_data', type_name='jsonb'): 13, Column(_name='run_history', type_name='bytea'): 14, Column(_name='run_extended_history', type_name='bytea'): 15, Column(_name='queue', type_name='smallint'): 16, Column(_name='status', type_name='smallint'): 17, Column(_name='priority', type_name='integer'): 18, Column(_name='start_time', type_name='timestamp'): 19, Column(_name='update_time', type_name='timestamp'): 20, Column(_name='worker', type_name='uuid'): 21, Column(_name='error_count', type_name='smallint'): 22, Column(_name='error', type_name='text'): 23, Column(_name='parent', type_name='uuid'): 24, Column(_name='command', type_name='jsonb'): 25}\n",
      "{Column(_name='experiment_id', type_name='uuid'): 0, Column(_name='run_timestamp', type_name='timestamp'): 1, Column(_name='run_id', type_name='uuid'): 2, Column(_name='job_id', type_name='uuid'): 3, Column(_name='seed', type_name='bigint'): 4, Column(_name='slurm_job_id', type_name='bigint'): 5, Column(_name='task_version', type_name='smallint'): 6, Column(_name='num_nodes', type_name='smallint'): 7, Column(_name='num_cpus', type_name='smallint'): 8, Column(_name='num_gpus', type_name='smallint'): 9, Column(_name='gpu_memory', type_name='integer'): 10, Column(_name='host_name', type_name='text'): 11, Column(_name='batch', type_name='text'): 12, Column(_name='run_data', type_name='jsonb'): 13, Column(_name='run_history', type_name='bytea'): 14, Column(_name='run_extended_history', type_name='bytea'): 15, Column(_name='queue', type_name='smallint'): 16, Column(_name='status', type_name='smallint'): 17, Column(_name='priority', type_name='integer'): 18, Column(_name='start_time', type_name='timestamp'): 19, Column(_name='update_time', type_name='timestamp'): 20, Column(_name='worker', type_name='uuid'): 21, Column(_name='error_count', type_name='smallint'): 22, Column(_name='error', type_name='text'): 23, Column(_name='parent', type_name='uuid'): 24, Column(_name='command', type_name='jsonb'): 25}\n"
     ]
    }
   ],
   "source": [
    "from psycopg import ClientCursor\n",
    "\n",
    "\n",
    "print(f\"run vars {vars(run)}\")\n",
    "\n",
    "columns = (\n",
    "    run\n",
    "    + ColumnGroup(*[c for c in job_status.columns if c.name != \"id\"])\n",
    "    + job_data.command\n",
    ")\n",
    "print(columns.names)\n",
    "\n",
    "\n",
    "def passthrough(row, index, value, column, data):\n",
    "    data[column.name] = value\n",
    "\n",
    "\n",
    "column_converters: List[Callable] = [passthrough for _ in columns]\n",
    "\n",
    "\n",
    "def flatten_json(json_obj, destination=None, parent_key=\"\", separator=\"_\"):\n",
    "    if isinstance(destination, dict):\n",
    "        flattened = destination\n",
    "    else:\n",
    "        flattened = {}\n",
    "\n",
    "    for key, value in json_obj.items():\n",
    "        new_key = f\"{parent_key}{separator}{key}\" if parent_key else key\n",
    "        if isinstance(value, dict):\n",
    "            flattened.update(flatten_json(value, new_key, separator=separator))\n",
    "        else:\n",
    "            flattened[new_key] = value\n",
    "    return flattened\n",
    "\n",
    "\n",
    "column_converters[\n",
    "    columns.get_index_of(job_data.command)\n",
    "] = lambda row, index, value, column, data: flatten_json(value, destination=data)\n",
    "column_converters[\n",
    "    columns.get_index_of(run.run_data)\n",
    "] = lambda row, index, value, column, data: flatten_json(value, destination=data)\n",
    "\n",
    "\n",
    "def parquet_to_dataframe(row, index, value, column, data):\n",
    "    with io.BytesIO(value) as buffer:\n",
    "        data[column.name] = (\n",
    "            pyarrow.parquet.read_table(pyarrow.PythonFile(buffer, mode=\"r\"))\n",
    "            .to_pandas()\n",
    "            .sort_values(by=\"epoch\")\n",
    "        )\n",
    "\n",
    "\n",
    "column_converters[columns.get_index_of(run.run_history)] = parquet_to_dataframe\n",
    "column_converters[columns.get_index_of(run.run_extended_history)] = parquet_to_dataframe\n",
    "\n",
    "\n",
    "dfs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(query_search):\n",
    "    with ConnectionManager(credentials) as connection:\n",
    "        query = psycopg.sql.SQL(\n",
    "            \"\"\"\n",
    "    SELECT\n",
    "        {columns}\n",
    "    FROM\n",
    "        {run},\n",
    "        {job_status},\n",
    "        {job_data}\n",
    "    WHERE\n",
    "        {run}.batch LIKE {pattern}\n",
    "        AND {job_status}.id = {run}.run_id\n",
    "        AND {job_status}.id = {job_data}.id\n",
    "        AND {job_status}.status = 2\n",
    "        AND {job_data}.command @> {json_data}::jsonb\n",
    "    LIMIT 2\n",
    "    \"\"\"\n",
    "        ).format(\n",
    "            columns=columns.columns_sql,\n",
    "            run=run.identifier,\n",
    "            job_status=job_status.identifier,\n",
    "            job_data=job_data.identifier,\n",
    "            pattern=sql.Literal(\"%energy%\"),\n",
    "            json_data=sql.Literal(query_search),\n",
    "        )\n",
    "\n",
    "        # with ClientCursor(connection) as c:\n",
    "        #     print(c.mogrify(query))\n",
    "\n",
    "        with connection.cursor(binary=True) as cursor:\n",
    "            cursor.execute(query, binary=True)\n",
    "\n",
    "            for row in cursor:\n",
    "                row_data = {}\n",
    "                for i, (column, column_converter) in enumerate(\n",
    "                    zip(columns, column_converters)\n",
    "                ):\n",
    "                    column_converter(row, i, row[i], column, row_data)\n",
    "\n",
    "                row_df = row_data[\"run_history\"]\n",
    "                row_df = row_df.join(\n",
    "                    row_data[\"run_extended_history\"], on=\"epoch\", how=\"left\", rsuffix=\"_\"\n",
    "                )\n",
    "                print(list(row_df.columns.values))\n",
    "                for k in (\"run_history\", \"run_extended_history\"):\n",
    "                    del row_data[k]\n",
    "\n",
    "                for k, v in row_data.items():\n",
    "                    if k in row_df:\n",
    "                        pass\n",
    "                    if isinstance(v, list):\n",
    "                        row_df[k] = [v] * len(row_df)\n",
    "                    else:\n",
    "                        row_df[k] = v\n",
    "                    # data.setdefault(k, []).append(v)\n",
    "                dfs.append(row_df)\n",
    "\n",
    "    data = pandas.concat(dfs)\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        for column in data.columns:\n",
    "            if isinstance(row[column], uuid.UUID):\n",
    "                data.at[index, column] = str(row[column])\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_accuracy', 'train_accuracy', 'test_loss', 'train_loss', 'epoch', 'test_cosine_similarity', 'train_cosine_similarity', 'test_kullback_leibler_divergence', 'train_kullback_leibler_divergence', 'epoch_']\n",
      "['test_accuracy', 'train_accuracy', 'test_loss', 'train_loss', 'epoch', 'test_cosine_similarity', 'train_cosine_similarity', 'test_kullback_leibler_divergence', 'train_kullback_leibler_divergence', 'epoch_']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1595: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1596: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1596: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1595: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1596: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/home/ctripp/dmp/env0/lib/python3.10/site-packages/pandas/io/formats/format.py:1596: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>test_cosine_similarity</th>\n",
       "      <th>train_cosine_similarity</th>\n",
       "      <th>test_kullback_leibler_divergence</th>\n",
       "      <th>train_kullback_leibler_divergence</th>\n",
       "      <th>epoch_</th>\n",
       "      <th>...</th>\n",
       "      <th>name</th>\n",
       "      <th>method</th>\n",
       "      <th>source</th>\n",
       "      <th>test_split</th>\n",
       "      <th>label_noise</th>\n",
       "      <th>validation_split</th>\n",
       "      <th>run_tags</th>\n",
       "      <th>class</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>early_stopping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.034250</td>\n",
       "      <td>2.384217</td>\n",
       "      <td>2.399859</td>\n",
       "      <td>1</td>\n",
       "      <td>0.315702</td>\n",
       "      <td>0.309997</td>\n",
       "      <td>2.352188</td>\n",
       "      <td>2.370012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>201_pol</td>\n",
       "      <td>shuffled_train_test_split</td>\n",
       "      <td>pmlb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.361667</td>\n",
       "      <td>0.197000</td>\n",
       "      <td>2.352203</td>\n",
       "      <td>2.370025</td>\n",
       "      <td>2</td>\n",
       "      <td>0.328296</td>\n",
       "      <td>0.320781</td>\n",
       "      <td>2.314635</td>\n",
       "      <td>2.336985</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>201_pol</td>\n",
       "      <td>shuffled_train_test_split</td>\n",
       "      <td>pmlb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.586333</td>\n",
       "      <td>0.468333</td>\n",
       "      <td>2.314649</td>\n",
       "      <td>2.336999</td>\n",
       "      <td>3</td>\n",
       "      <td>0.345632</td>\n",
       "      <td>0.334882</td>\n",
       "      <td>2.266197</td>\n",
       "      <td>2.296302</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>201_pol</td>\n",
       "      <td>shuffled_train_test_split</td>\n",
       "      <td>pmlb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635333</td>\n",
       "      <td>0.595083</td>\n",
       "      <td>2.266211</td>\n",
       "      <td>2.296317</td>\n",
       "      <td>4</td>\n",
       "      <td>0.370784</td>\n",
       "      <td>0.354888</td>\n",
       "      <td>2.201205</td>\n",
       "      <td>2.242655</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>201_pol</td>\n",
       "      <td>shuffled_train_test_split</td>\n",
       "      <td>pmlb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.637667</td>\n",
       "      <td>0.618833</td>\n",
       "      <td>2.201220</td>\n",
       "      <td>2.242668</td>\n",
       "      <td>5</td>\n",
       "      <td>0.407779</td>\n",
       "      <td>0.384186</td>\n",
       "      <td>2.113321</td>\n",
       "      <td>2.170389</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>201_pol</td>\n",
       "      <td>shuffled_train_test_split</td>\n",
       "      <td>pmlb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.884571</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.463969</td>\n",
       "      <td>0.352319</td>\n",
       "      <td>2996</td>\n",
       "      <td>0.898308</td>\n",
       "      <td>0.914486</td>\n",
       "      <td>0.448271</td>\n",
       "      <td>0.350147</td>\n",
       "      <td>2997.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>shuffled_train_test_split</td>\n",
       "      <td>pmlb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.884571</td>\n",
       "      <td>0.902036</td>\n",
       "      <td>0.463970</td>\n",
       "      <td>0.352322</td>\n",
       "      <td>2997</td>\n",
       "      <td>0.898307</td>\n",
       "      <td>0.914497</td>\n",
       "      <td>0.448339</td>\n",
       "      <td>0.350109</td>\n",
       "      <td>2998.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>shuffled_train_test_split</td>\n",
       "      <td>pmlb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.884714</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.464071</td>\n",
       "      <td>0.352285</td>\n",
       "      <td>2998</td>\n",
       "      <td>0.898291</td>\n",
       "      <td>0.914491</td>\n",
       "      <td>0.448355</td>\n",
       "      <td>0.350124</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>shuffled_train_test_split</td>\n",
       "      <td>pmlb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.884643</td>\n",
       "      <td>0.902125</td>\n",
       "      <td>0.464062</td>\n",
       "      <td>0.352299</td>\n",
       "      <td>2999</td>\n",
       "      <td>0.898301</td>\n",
       "      <td>0.914496</td>\n",
       "      <td>0.448314</td>\n",
       "      <td>0.350109</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>shuffled_train_test_split</td>\n",
       "      <td>pmlb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.884429</td>\n",
       "      <td>0.902071</td>\n",
       "      <td>0.464021</td>\n",
       "      <td>0.352283</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>shuffled_train_test_split</td>\n",
       "      <td>pmlb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_accuracy  train_accuracy  test_loss  train_loss  epoch  \\\n",
       "0          0.077000        0.034250   2.384217    2.399859      1   \n",
       "1          0.361667        0.197000   2.352203    2.370025      2   \n",
       "2          0.586333        0.468333   2.314649    2.336999      3   \n",
       "3          0.635333        0.595083   2.266211    2.296317      4   \n",
       "4          0.637667        0.618833   2.201220    2.242668      5   \n",
       "...             ...             ...        ...         ...    ...   \n",
       "2995       0.884571        0.902000   0.463969    0.352319   2996   \n",
       "2996       0.884571        0.902036   0.463970    0.352322   2997   \n",
       "2997       0.884714        0.902000   0.464071    0.352285   2998   \n",
       "2998       0.884643        0.902125   0.464062    0.352299   2999   \n",
       "2999       0.884429        0.902071   0.464021    0.352283   3000   \n",
       "\n",
       "      test_cosine_similarity  train_cosine_similarity  \\\n",
       "0                   0.315702                 0.309997   \n",
       "1                   0.328296                 0.320781   \n",
       "2                   0.345632                 0.334882   \n",
       "3                   0.370784                 0.354888   \n",
       "4                   0.407779                 0.384186   \n",
       "...                      ...                      ...   \n",
       "2995                0.898308                 0.914486   \n",
       "2996                0.898307                 0.914497   \n",
       "2997                0.898291                 0.914491   \n",
       "2998                0.898301                 0.914496   \n",
       "2999                     NaN                      NaN   \n",
       "\n",
       "      test_kullback_leibler_divergence  train_kullback_leibler_divergence  \\\n",
       "0                             2.352188                           2.370012   \n",
       "1                             2.314635                           2.336985   \n",
       "2                             2.266197                           2.296302   \n",
       "3                             2.201205                           2.242655   \n",
       "4                             2.113321                           2.170389   \n",
       "...                                ...                                ...   \n",
       "2995                          0.448271                           0.350147   \n",
       "2996                          0.448339                           0.350109   \n",
       "2997                          0.448355                           0.350124   \n",
       "2998                          0.448314                           0.350109   \n",
       "2999                               NaN                                NaN   \n",
       "\n",
       "      epoch_  ...     name                     method source test_split  \\\n",
       "0        2.0  ...  201_pol  shuffled_train_test_split   pmlb        0.2   \n",
       "1        3.0  ...  201_pol  shuffled_train_test_split   pmlb        0.2   \n",
       "2        4.0  ...  201_pol  shuffled_train_test_split   pmlb        0.2   \n",
       "3        5.0  ...  201_pol  shuffled_train_test_split   pmlb        0.2   \n",
       "4        6.0  ...  201_pol  shuffled_train_test_split   pmlb        0.2   \n",
       "...      ...  ...      ...                        ...    ...        ...   \n",
       "2995  2997.0  ...    mnist  shuffled_train_test_split   pmlb        0.2   \n",
       "2996  2998.0  ...    mnist  shuffled_train_test_split   pmlb        0.2   \n",
       "2997  2999.0  ...    mnist  shuffled_train_test_split   pmlb        0.2   \n",
       "2998  3000.0  ...    mnist  shuffled_train_test_split   pmlb        0.2   \n",
       "2999     NaN  ...    mnist  shuffled_train_test_split   pmlb        0.2   \n",
       "\n",
       "      label_noise  validation_split  run_tags  class  learning_rate  \\\n",
       "0             0.0               0.0      None   Adam         0.0001   \n",
       "1             0.0               0.0      None   Adam         0.0001   \n",
       "2             0.0               0.0      None   Adam         0.0001   \n",
       "3             0.0               0.0      None   Adam         0.0001   \n",
       "4             0.0               0.0      None   Adam         0.0001   \n",
       "...           ...               ...       ...    ...            ...   \n",
       "2995          0.0               0.0      None   Adam         0.0001   \n",
       "2996          0.0               0.0      None   Adam         0.0001   \n",
       "2997          0.0               0.0      None   Adam         0.0001   \n",
       "2998          0.0               0.0      None   Adam         0.0001   \n",
       "2999          0.0               0.0      None   Adam         0.0001   \n",
       "\n",
       "      early_stopping  \n",
       "0               None  \n",
       "1               None  \n",
       "2               None  \n",
       "3               None  \n",
       "4               None  \n",
       "...              ...  \n",
       "2995            None  \n",
       "2996            None  \n",
       "2997            None  \n",
       "2998            None  \n",
       "2999            None  \n",
       "\n",
       "[24000 rows x 79 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(\"{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tqdm as tqmd\n",
    "def save_data(queries:list):\n",
    "    for query in tqmd.tqdm(queries):\n",
    "        data = get_data(query)\n",
    "        # convert to pyarrow table\n",
    "        table = pa.Table.from_pandas(data)\n",
    "\n",
    "        # write to distributed parquet file saved as ['name','depth','size','shape']\n",
    "        pq.write_to_dataset(table, root_path='/projects/gcomp/jgafur/dataset/', partition_cols=['name','shape','depth','size'])\n",
    "        del data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqmd\n",
    "from multiprocessing import Pool\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "def save_parallel(query):\n",
    "    data = get_data(query)\n",
    "    table = pa.Table.from_pandas(data)\n",
    "    pq.write_to_dataset(table, root_path='/projects/gcomp/jgafur/dataset/', partition_cols=['name', 'shape', 'depth', 'size'])\n",
    "    del data\n",
    "\n",
    "def save_data_parallelized(queries):\n",
    "    with Pool() as pool:\n",
    "        list(tqmd.tqdm(pool.imap(save_parallel, queries), total=len(queries)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_json(**kwargs):\n",
    "    # Given dictionary\n",
    "    given_dict = {}\n",
    "\n",
    "    # Update the given dictionary with user input\n",
    "    given_dict.update(kwargs)\n",
    "\n",
    "    # Convert the updated dictionary to JSON\n",
    "    json_result = json.dumps(given_dict, indent=2)\n",
    "\n",
    "    return json_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"splice\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"sleep\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"529_pollen\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"banana\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"201_pol\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"wine_quality_white\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"mnist\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"nursery\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"connect_4\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "\n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"537_houses\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"294_satellite_image\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"adult\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    SELECT\n",
      "        \"experiment_id\",\"run_timestamp\",\"run_id\",\"job_id\",\"seed\",\"slurm_job_id\",\"task_version\",\"num_nodes\",\"num_cpus\",\"num_gpus\",\"gpu_memory\",\"host_name\",\"batch\",\"run_data\",\"run_history\",\"run_extended_history\",\"queue\",\"status\",\"priority\",\"start_time\",\"update_time\",\"worker\",\"error_count\",\"error\",\"parent\",\"command\"\n",
      "    FROM\n",
      "        \"run\",\n",
      "        \"job_status\",\n",
      "        \"job_data\"\n",
      "    WHERE\n",
      "        \"run\".batch LIKE '%energy%'\n",
      "        AND \"job_status\".id = \"run\".run_id\n",
      "        AND \"job_status\".id = \"job_data\".id\n",
      "        AND \"job_status\".status = 2\n",
      "        AND \"job_data\".command @> '{\n",
      "  \"dataset\": {\n",
      "    \"name\": \"505_tecator\"\n",
      "  }\n",
      "}'::jsonb\n",
      "    ORDER BY\n",
      "        experiment_id, run_id;\n",
      "    \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [02:56<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/nopt/nrel/apps/anaconda/mini_4.9.2/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1a63456fa591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0msave_data_parallelized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_search1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_search13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-f47b6ed44765>\u001b[0m in \u001b[0;36msave_data_parallelized\u001b[0;34m(queries)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_data_parallelized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_parallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nopt/nrel/apps/anaconda/mini_4.9.2/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nopt/nrel/apps/anaconda/mini_4.9.2/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    856\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nopt/nrel/apps/anaconda/mini_4.9.2/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query_search1 = get_json( dataset={\"name\": \"sleep\"}\n",
    "        )\n",
    "\n",
    "query_search2 = get_json(dataset={\"name\":\"banana\"},\n",
    "        )\n",
    "\n",
    "query_search3 = get_json(dataset={\"name\":\"connect_4\"},\n",
    "        )\n",
    "\n",
    "query_search4 = get_json(dataset={\"name\":\"mnist\"},\n",
    "        )\n",
    "\n",
    "query_search5 = get_json(dataset={\"name\":\"nursery\"},\n",
    "        )\n",
    "\n",
    "query_search6 = get_json(dataset={\"name\":\"splice\"},\n",
    "        )\n",
    "\n",
    "query_search7 = get_json(dataset={\"name\":\"wine_quality_white\"},\n",
    "        )\n",
    "\n",
    "query_search8 = get_json(dataset={\"name\":\"201_pol\"},\n",
    "        )\n",
    "\n",
    "query_search9 = get_json(dataset={\"name\":\"294_satellite_image\"},\n",
    "        )\n",
    "\n",
    "query_search10 = get_json(dataset={\"name\":\"505_tecator\"},\n",
    "        )\n",
    "\n",
    "query_search11 = get_json(dataset={\"name\":\"529_pollen\"},\n",
    "        )\n",
    "\n",
    "query_search12 = get_json(dataset={\"name\":\"537_houses\"},\n",
    "        )\n",
    "\n",
    "query_search13 = get_json(dataset={\"name\":\"adult\"},\n",
    "        )\n",
    "\n",
    "\n",
    "save_data_parallelized([query_search1, query_search2, query_search3, query_search4, query_search5, query_search6, query_search7, query_search8, query_search9, query_search10, query_search11, query_search12, query_search13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
